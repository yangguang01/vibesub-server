import os
import json
import asyncio
import re
import yt_dlp
import datetime
import threading

from pathlib import Path
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from openai import AsyncOpenAI
import aiohttp
from functools import wraps
import openai
import httpx
import assemblyai as aai

from app.common.core.config import REPLICATE_API_TOKEN, DEEPSEEK_API_KEY, RETRY_ATTEMPTS, BATCH_SIZE, MAX_CONCURRENT_TASKS, API_TIMEOUT, OPENAI_API_KEY, ASSEMBLYAI_API_KEY,PROXY_URL
from app.common.core.logging import logger

# å…¨å±€è°ƒè¯•è®°å½•å­˜å‚¨
debug_records = []
debug_lock = threading.Lock()

def add_debug_record(video_id, chunk_info, input_data, output_data, result_info, attempt_type="initial"):
    """
    æ·»åŠ è°ƒè¯•è®°å½•åˆ°å…¨å±€åˆ—è¡¨
    
    Args:
        video_id: è§†é¢‘ID
        chunk_info: å—ä¿¡æ¯ (first_item_number, end_item_number, expected_lines)
        input_data: è¾“å…¥æ•°æ® (system_prompt, user_content)
        output_data: è¾“å‡ºæ•°æ® (raw_response, parsed_json, actual_lines)
        result_info: ç»“æœä¿¡æ¯ (success, line_count_match, error_message)
        attempt_type: å°è¯•ç±»å‹ ("initial", "retry")
    """
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    record = {
        'timestamp': timestamp,
        'video_id': video_id,
        'chunk_first': chunk_info['first'],
        'chunk_end': chunk_info['end'],
        'attempt_type': attempt_type,
        'content': f"""[{timestamp}] VIDEO: {video_id} | CHUNK: {chunk_info['first']}-{chunk_info['end']} | ATTEMPT: {attempt_type}
INPUT_LINES: {chunk_info['expected']}
{input_data['user_content']}
---
OUTPUT_LINES: {output_data.get('actual_lines', 'ERROR')} (Expected: {chunk_info['expected']})
{output_data.get('formatted_output', 'ERROR')}
---
RESULT: {'SUCCESS' if result_info['success'] else 'FAILED'} ({chunk_info['expected']}â†’{output_data.get('actual_lines', '?')}) {result_info.get('error_message', '')}
{'='*80}
"""
    }
    
    with debug_lock:
        debug_records.append(record)

def get_debug_records_text():
    """
    è·å–æ‰€æœ‰è°ƒè¯•è®°å½•çš„æ–‡æœ¬å†…å®¹ï¼ŒæŒ‰CHUNKç¼–å·æ’åº
    
    Returns:
        str: æ ¼å¼åŒ–çš„è°ƒè¯•è®°å½•æ–‡æœ¬
    """
    with debug_lock:
        if not debug_records:
            return "No debug records found.\n"
        
        # æŒ‰CHUNKç¼–å·æ’åºï¼šå…ˆæŒ‰chunk_firstï¼Œå†æŒ‰attempt_type (initialåœ¨å‰ï¼Œretryåœ¨å)
        sorted_records = sorted(debug_records, key=lambda x: (
            x['chunk_first'], 
            0 if x['attempt_type'] == 'initial' else 1,  # initialæ’åœ¨retryå‰é¢
            x['timestamp']
        ))
        
        header = f"""=== LLM Translation Debug Records ===
Generated: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
Total Records: {len(debug_records)}
Sorted by: CHUNK number, then attempt type (initial â†’ retry)
{'='*80}

"""
        return header + '\n'.join(record['content'] for record in sorted_records)

def clear_debug_records():
    """æ¸…ç©ºè°ƒè¯•è®°å½•"""
    with debug_lock:
        debug_records.clear()

async def save_debug_records_to_storage(video_id, bucket):
    """
    å°†è°ƒè¯•è®°å½•ä¿å­˜åˆ° Firebase Storage
    
    Args:
        video_id: è§†é¢‘ID
        bucket: Firebase Storage bucket å®ä¾‹
    
    Returns:
        str: ä¸Šä¼ åçš„æ–‡ä»¶URLï¼Œå¦‚æœæ²¡æœ‰è®°å½•åˆ™è¿”å›None
    """
    try:
        debug_text = get_debug_records_text()
        
        # å¦‚æœæ²¡æœ‰è°ƒè¯•è®°å½•ï¼Œç›´æ¥è¿”å›
        if debug_text.strip() == "No debug records found.":
            logger.info("æ²¡æœ‰è°ƒè¯•è®°å½•éœ€è¦ä¿å­˜")
            return None
        
        # ä¸Šä¼ åˆ° Firebase Storage
        debug_blob = bucket.blob(f"debug_records/{video_id}_translation_debug.txt")
        debug_blob.upload_from_string(
            debug_text,
            content_type="text/plain; charset=utf-8"
        )
        
        logger.info(f"è°ƒè¯•è®°å½•å·²ä¿å­˜åˆ° Firebase Storage: debug_records/{video_id}_translation_debug.txt")
        return debug_blob.public_url
        
    except Exception as e:
        logger.error(f"ä¿å­˜è°ƒè¯•è®°å½•åˆ° Firebase Storage å¤±è´¥: {str(e)}", exc_info=True)
        return None


def download_audio_webm(url, file_path):
    """
    ä»æŒ‡å®š URL ä¸‹è½½éŸ³é¢‘ï¼ˆä»…ä¸‹è½½ webm æ ¼å¼çš„éŸ³é¢‘æµï¼‰
    
    å‚æ•°:
        url (str): åª’ä½“èµ„æºçš„ URL
        file_path (Path): ä¿å­˜éŸ³é¢‘çš„è·¯å¾„
        
    è¿”å›:
        Path: ä¸‹è½½åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    try:
        logger.info(f"å¼€å§‹ä¸‹è½½è§†é¢‘: {url}")
        
        ydl_opts = {
            'format': 'bestaudio[ext=webm]',
            'outtmpl': str(file_path),
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            },
            'force_ipv4': True,
            'proxy': 'socks5://8t4v58911-region-US-sid-JaboGcGm-t-5:wl34yfx7@us2.cliproxy.io:443'
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])
            
        logger.info(f"è§†é¢‘ä¸‹è½½å®Œæˆ: {file_path}")
        return file_path
    except Exception as e:
        logger.error(f"ä¸‹è½½å¤±è´¥: {str(e)}", exc_info=True)
        raise


def get_video_info(url):
    """
    è·å–YouTubeè§†é¢‘ä¿¡æ¯
    
    å‚æ•°:
        url (str): YouTube URL
        
    è¿”å›:
        dict: è§†é¢‘ä¿¡æ¯å­—å…¸
    """
    try:
        logger.info(f"è·å–è§†é¢‘ä¿¡æ¯: {url}")
        
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'skip_download': True,
            'forcejson': True,
            'force_ipv4': True,
            'proxy': 'socks5://8t4v58911-region-US-sid-JaboGcGm-t-5:wl34yfx7@us2.cliproxy.io:443',
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            
        # ç¡®ä¿è¿”å›çš„ä¿¡æ¯ä¸­åŒ…å«è§†é¢‘ID
        video_data = {
            'title': info.get('title', 'Unknown'),
            'id': info.get('id', ''),  # æå–è§†é¢‘ID
            'channel': info.get('channel', 'Unknown'),
            'duration': info.get('duration', 0),
            # å…¶ä»–éœ€è¦çš„ä¿¡æ¯...
        }
        
        logger.info(f"è·å–è§†é¢‘ä¿¡æ¯æˆåŠŸ: {video_data['title']}, ID: {video_data['id']}")
        return video_data
    except Exception as e:
        logger.error(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}", exc_info=True)
        raise

# 250403æ›´æ–°ï¼šæ–°å¢get_video_info_and_downloadå‡½æ•°ï¼ŒåŒæ—¶è·å–ä¿¡æ¯å¹¶ä¸‹è½½éŸ³é¢‘
async def get_video_info_and_download_async(url, file_path):
    """
    å¼‚æ­¥è·å–YouTubeè§†é¢‘ä¿¡æ¯å¹¶ä¸‹è½½

    å‚æ•°:
        url (str): YouTube URL
        file_path (str/Path): ç›®æ ‡æ–‡ä»¶è·¯å¾„

    è¿”å›:
        dict: è§†é¢‘ä¿¡æ¯å­—å…¸
    """
    logger.info("ä»»åŠ¡å¼€å§‹! éŸ³é¢‘ä¸‹è½½ä¸­...")
    
    # å®šä¹‰ä¸€ä¸ªåŒæ­¥å‡½æ•°ç”¨äºåœ¨çº¿ç¨‹ä¸­æ‰§è¡Œ
    def download_video():
        logger.info(f"å¼€å§‹åœ¨å•ç‹¬çº¿ç¨‹ä¸­ä¸‹è½½è§†é¢‘: {url}")
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'format': 'bestaudio[ext=webm]',
            'outtmpl': str(file_path),
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            },
            'force_ipv4': True,
            #'proxy': 'socks5://8t4v58911-region-US-sid-JaboGcGm-t-5:wl34yfx7@us2.cliproxy.io:443',
        }
        if PROXY_URL:
            ydl_opts['proxy'] = PROXY_URL
            logger.info(f"ä½¿ç”¨ä»£ç†: {PROXY_URL}")

        print(file_path)
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=True)
        logger.info(f"è§†é¢‘ä¸‹è½½å®Œæˆ: {file_path}")
        return info
    
    # ä½¿ç”¨asyncio.to_threadåœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­æ‰§è¡Œä¸‹è½½æ“ä½œ
    logger.info("å¼€å§‹åœ¨å•ç‹¬çº¿ç¨‹ä¸­æ‰§è¡Œä¸‹è½½æ“ä½œ")
    info = await asyncio.to_thread(download_video)
    
    # å¤„ç†å¹¶è¿”å›è§†é¢‘ä¿¡æ¯
    video_data = {
        'title': info.get('title', 'Unknown'),
        'id': info.get('id', ''),  # æå–è§†é¢‘ID
        'channel': info.get('channel', 'Unknown'), 
        'duration': info.get('duration', 0),
        # å…¶ä»–éœ€è¦çš„ä¿¡æ¯...
    }
    
    return video_data


@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=30),
    retry=retry_if_exception_type((yt_dlp.utils.DownloadError, OSError, ConnectionError))
)
def get_video_info_and_download(url):
    """
    ä» YouTube ä¸‹è½½éŸ³é¢‘åˆ°å½“å‰å·¥ä½œç›®å½•ï¼Œæ–‡ä»¶åä¸º <video_id>.webmï¼Œ
    å¹¶è¿”å›è§†é¢‘ä¿¡æ¯å’Œä¸‹è½½åçš„æ–‡ä»¶åã€‚

    Args:
        url (str): YouTube è§†é¢‘é“¾æ¥

    Returns:
        tuple:
            video_data (dict): åŒ…å« title, id, channel
            filename (str): ä¸‹è½½åˆ°æœ¬åœ°çš„æ–‡ä»¶å (ä¾‹å¦‚ "abc123.webm")
    """
    logger.info("ä»»åŠ¡å¼€å§‹ï¼éŸ³é¢‘ä¸‹è½½ä¸­...")

    # ç›´æ¥åœ¨å½“å‰ç›®å½•ä¸‹ï¼Œä»¥è§†é¢‘ ID ä½œä¸ºæ–‡ä»¶åï¼Œåç¼€ç”± format å†³å®šï¼ˆè¿™é‡Œå›ºå®š webmï¼‰
    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'format': 'bestaudio[abr<=128]/bestaudio',
        'outtmpl': '%(id)s.%(ext)s',
        'http_headers': {
            'User-Agent': (
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
                'AppleWebKit/537.36 (KHTML, like Gecko) '
                'Chrome/120.0.0.0 Safari/537.36'
            ),
        },
        'force_ipv4': True,
        # ğŸ”¥ æ·»åŠ è¶…æ—¶æ§åˆ¶
        'socket_timeout': 60,  # 60ç§’è¿æ¥è¶…æ—¶
        'retries': 2,  # yt-dlpå†…éƒ¨é‡è¯•2æ¬¡
    }
    if PROXY_URL:
        ydl_opts['proxy'] = PROXY_URL
        logger.info(f"ä½¿ç”¨ä»£ç†: {PROXY_URL}")

    logger.info(f"å¼€å§‹ä¸‹è½½è§†é¢‘: {url}")
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            # ğŸ”¥ å…ˆæå–ä¿¡æ¯ï¼Œæ£€æŸ¥è§†é¢‘å¯ç”¨æ€§
            info = ydl.extract_info(url, download=False)
            
            # æ£€æŸ¥è§†é¢‘çŠ¶æ€
            if info.get('is_live'):
                raise ValueError("ä¸æ”¯æŒç›´æ’­è§†é¢‘")
            if info.get('availability') in ['private', 'premium_only', 'subscriber_only']:
                raise ValueError(f"è§†é¢‘ä¸å¯è®¿é—®: {info.get('availability')}")
            
            # æå–å¹¶ä¸‹è½½
            info = ydl.extract_info(url, download=True)
            # ydl.prepare_filename ä¼šä½¿ç”¨ outtmpl è§„åˆ™ï¼Œè¿”å›å®é™…å†™å…¥çš„æ–‡ä»¶è·¯å¾„
            filepath = ydl.prepare_filename(info)

        video_id = info.get('id', '')
        # filepath å¯èƒ½åŒ…å«è·¯å¾„ï¼Œè¿™é‡Œåªå–æ–‡ä»¶å
        filename = os.path.basename(filepath)

        video_data = {
            'title': info.get('title', 'Unknown'),
            'id': video_id,
            'channel': info.get('channel', 'Unknown'),
        }

        logger.info(f"è§†é¢‘ä¸‹è½½å®Œæˆ: {filename}")
        return video_data, filename
        
    except yt_dlp.utils.DownloadError as e:
        error_msg = str(e)
        logger.error(f"yt-dlpä¸‹è½½é”™è¯¯: {error_msg}")
        
        # ğŸ”¥ åˆ†ç±»å¤„ç†ä¸åŒç±»å‹çš„ä¸‹è½½é”™è¯¯
        if any(keyword in error_msg.lower() for keyword in [
            "bytes missing", "eoferror", "connection reset", "timeout",
            "http error 5", "temporary failure"
        ]):
            # è¿™äº›æ˜¯ä¸´æ—¶æ€§ç½‘ç»œé”™è¯¯ï¼Œå¯ä»¥é‡è¯•
            logger.warning(f"æ£€æµ‹åˆ°ä¸´æ—¶æ€§ç½‘ç»œé”™è¯¯ï¼Œå°†é‡è¯•: {error_msg}")
            raise  # è®©tenacityé‡è¯•
        else:
            # æ°¸ä¹…æ€§é”™è¯¯ï¼Œä¸é‡è¯•
            logger.error(f"æ£€æµ‹åˆ°æ°¸ä¹…æ€§é”™è¯¯ï¼Œä¸é‡è¯•: {error_msg}")
            raise ValueError(f"è§†é¢‘ä¸‹è½½å¤±è´¥: {error_msg}")
            
    except Exception as e:
        logger.error(f"è§†é¢‘ä¸‹è½½å¼‚å¸¸: {str(e)}")
        raise


def transcribe_audio_with_assemblyai(filename: str) -> list:
    """
    ä½¿ç”¨ AssemblyAI è½¬å½•å½“å‰å·¥ä½œç›®å½•ä¸‹çš„éŸ³é¢‘æ–‡ä»¶ï¼Œ
    æ–‡ä»¶åç›´æ¥ä¼ å…¥ï¼ˆä¾‹å¦‚ 'abc123.webm'ï¼‰ï¼Œè¿”å›å¥å­åˆ—è¡¨ã€‚

    Args:
        filename (str): å½“å‰ç›®å½•ä¸‹çš„éŸ³é¢‘æ–‡ä»¶å

    Returns:
        List[Sentence]: AssemblyAI è¿”å›çš„å¥å­å¯¹è±¡åˆ—è¡¨
    """
    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    filepath = os.path.abspath(filename)
    if not os.path.isfile(filepath):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶: {filepath}")

    # 2. è·å–å¹¶è®¾ç½® API Key
    api_key = ASSEMBLYAI_API_KEY
    if not api_key:
        raise ValueError(f"æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ è¯·ç¡®ä¿å·²è®¾ç½®APIå¯†é’¥")

    logger.info(f"å¼€å§‹ä½¿ç”¨ AssemblyAI è½¬å½•éŸ³é¢‘: {filename}")

    # 3. æ–°å»ºè½¬å½•å™¨å¹¶ä¸Šä¼ æ–‡ä»¶
    transcriber = aai.Transcriber()
    try:
        # ç›´æ¥æŠŠæ–‡ä»¶è·¯å¾„ä¼ ç»™ SDKï¼Œè®©å®ƒå¤„ç†ä¸Šä¼ å’Œè½¬å†™
        transcript = transcriber.transcribe(filepath)
    except Exception as e:
        logger.error(f"è½¬å†™å¤±è´¥: {e}", exc_info=True)
        raise

    logger.info("éŸ³é¢‘è½¬å†™å®Œæˆ")

    # 4. æå–å¹¶è¿”å›å¥å­åˆ—è¡¨
    try:
        sentences = transcript.get_sentences()
    except AttributeError:
        # å¦‚æœ SDK ç‰ˆæœ¬ç¨æœ‰ä¸åŒï¼Œä¹Ÿå¯å°è¯• transcript.sentences
        sentences = getattr(transcript, "sentences", [])
    return sentences

def convert_AssemblyAI_to_srt(sentences):
    """
    AssemblyAIé…å¥—å‡½æ•°
    å°†å¥å­åˆ—è¡¨è½¬æ¢ä¸ºSRTæ ¼å¼çš„å­—å¹•
    
    å‚æ•°:
        sentences: åŒ…å«text, startå’Œendå±æ€§çš„å¥å­å¯¹è±¡åˆ—è¡¨
    
    è¿”å›:
        SRTæ ¼å¼çš„å­—ç¬¦ä¸²
    """
    srt_content = ""
    
    for i, sentence in enumerate(sentences, 1):
        # å°†æ¯«ç§’è½¬æ¢ä¸ºSRTæ—¶é—´æ ¼å¼ (HH:MM:SS,mmm)
        start_time = format_time_AssemblyAI(sentence.start)
        end_time = format_time_AssemblyAI(sentence.end)
        
        # åˆ›å»ºSRTæ¡ç›®
        srt_content += f"{i}\n"
        srt_content += f"{start_time} --> {end_time}\n"
        srt_content += f"{sentence.text}\n\n"
    
    return srt_content.strip()

def format_time_AssemblyAI(milliseconds):
    """
    å°†æ¯«ç§’è½¬æ¢ä¸ºSRTæ—¶é—´æ ¼å¼ (HH:MM:SS,mmm)
    
    å‚æ•°:
        milliseconds: æ¯«ç§’æ•°
    
    è¿”å›:
        æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
    """
    # è½¬æ¢ä¸ºåˆé€‚çš„å•ä½
    seconds, milliseconds = divmod(milliseconds, 1000)
    minutes, seconds = divmod(seconds, 60)
    hours, minutes = divmod(minutes, 60)
    
    # è¿”å›æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
    return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"


def format_time(seconds):
    """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ ¼å¼çš„æ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º hh:mm:ss,mmm"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    milliseconds = int(round((seconds - int(seconds)) * 1000))
    return f"{hours:02}:{minutes:02}:{secs:02},{milliseconds:03}"


def json_to_srt(data):
    """ä» JSON æ•°æ®ä¸­æå– segments å­—æ®µï¼Œè½¬æ¢ä¸º SRT æ ¼å¼çš„æ–‡æœ¬"""
    srt_lines = []
    for idx, segment in enumerate(data.get("segments", []), start=1):
        start_time = format_time(segment["start"])
        end_time = format_time(segment["end"])
        text = segment["text"]
        srt_lines.append(str(idx))
        srt_lines.append(f"{start_time} --> {end_time}")
        srt_lines.append(text)
        srt_lines.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”ä¸åŒå­—å¹•æ®µ
    return "\n".join(srt_lines)

# 250403æ›´æ–°ï¼šç›´æ¥ä½¿ç”¨asr_resultä¸­çš„å¥å­ï¼Œä¸å†åˆå¹¶çŸ­å¥å­ã€‚å› æ­¤åˆ é™¤æ­¤å‡½æ•°
# def merge_incomplete_sentences(subtitles):
#     """å°†è‹±æ–‡å­—å¹•ä¸­çš„å†…å®¹åˆå¹¶ä¸ºå®Œæ•´å¥å­"""
#     # æŒ‰è¡Œåˆ†å‰²å­—å¹•æ–‡æœ¬
    lines = [line.strip() for line in subtitles.split('\n') if line.strip()]

    # å­˜å‚¨åˆå¹¶åçš„å¥å­
    merged_sentences = []
    current_sentence = ''

    for line in lines:
        if not line.isdigit() and '-->' not in line and line.strip() != '':
            # æ·»åŠ å½“å‰è¡Œåˆ°å½“å‰å¥å­
            current_sentence += ' ' + line if current_sentence else line

            # æ£€æŸ¥æ˜¯å¦ä¸ºå®Œæ•´å¥å­
            if any(current_sentence.endswith(symbol) for symbol in ['.', '?', '!']):
                merged_sentences.append(current_sentence)
                current_sentence = ''

    # ç¡®ä¿æœ€åä¸€å¥ä¹Ÿè¢«æ·»åŠ ï¼ˆå¦‚æœå®ƒæ˜¯å®Œæ•´çš„ï¼‰
    if current_sentence:
        merged_sentences.append(current_sentence)

    # å°†æ¯ä¸ªå¥å­è½¬æ¢ä¸ºå­—å…¸ï¼Œå¹¶æ·»åŠ åºå·
    numbered_and_sentences = {i: sentence for i, sentence in enumerate(merged_sentences, start=1)}

    return numbered_and_sentences

# 250403æ›´æ–°ï¼šæ–°å¢extract_asr_sentenceså‡½æ•°
def extract_asr_sentences(srt_content):
  """
  ä» SRT æ ¼å¼çš„å­—å¹•æ–‡æœ¬ä¸­æå–è‹±æ–‡å¥å­ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ä¸€ä¸ªå¸¦æœ‰åºå·çš„å­—å…¸ä¸­ã€‚

  Args:
    srt_content: SRT æ ¼å¼çš„å­—å¹•æ–‡æœ¬å­—ç¬¦ä¸²ã€‚

  Returns:
    ä¸€ä¸ªå­—å…¸ï¼Œé”®æ˜¯å¥å­åºå·ï¼Œå€¼æ˜¯å¯¹åº”çš„è‹±æ–‡å¥å­ã€‚
  """
  sentences = {}
  pattern = r"(\d+)\n.*? --> .*?\n(.*?)\n"  # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¥å­åºå·å’Œå†…å®¹
  matches = re.findall(pattern, srt_content, re.DOTALL)
  for match in matches:
      sentences[int(match[0])] = match[1].strip()
  return sentences


# é€šç”¨çš„å¼‚æ­¥é‡è¯•è£…é¥°å™¨
def async_retry(max_attempts=None, exceptions=None):
    """æ™ºèƒ½å¼‚æ­¥å‡½æ•°é‡è¯•è£…é¥°å™¨"""
    if max_attempts is None:
        max_attempts = RETRY_ATTEMPTS
    if exceptions is None:
        exceptions = (Exception,)
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    error_msg = str(e).lower()
                    
                    # ğŸ”¥ æ™ºèƒ½é”™è¯¯åˆ†ç±»ï¼šæŸäº›é”™è¯¯ä¸å€¼å¾—é‡è¯•
                    non_retryable_errors = [
                        "invalid api key", "authentication failed", "permission denied",
                        "model not found", "invalid request", "quota exceeded",
                        "content policy violation", "invalid json", "malformed request"
                    ]
                    
                    if any(err in error_msg for err in non_retryable_errors):
                        logger.error(f"æ£€æµ‹åˆ°ä¸å¯é‡è¯•é”™è¯¯: {str(e)}")
                        raise e
                    
                    # ğŸ”¥ åŠ¨æ€è°ƒæ•´ç­‰å¾…æ—¶é—´
                    if "rate limit" in error_msg or "too many requests" in error_msg:
                        # é™æµé”™è¯¯ï¼šæ›´é•¿ç­‰å¾…æ—¶é—´
                        wait_time = min(5 * (2 ** attempt), 60)
                    elif "timeout" in error_msg or "connection" in error_msg:
                        # ç½‘ç»œé”™è¯¯ï¼šæ ‡å‡†ç­‰å¾…æ—¶é—´
                        wait_time = min(2 * (2 ** attempt), 16)
                    else:
                        # å…¶ä»–é”™è¯¯ï¼šå¿«é€Ÿé‡è¯•
                        wait_time = min(1 * (2 ** attempt), 8)
                    
                    if attempt < max_attempts - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        logger.warning(f"å°è¯• {attempt+1}/{max_attempts} å¤±è´¥: {str(e)}ï¼Œç­‰å¾… {wait_time}ç§’åé‡è¯•")
                        await asyncio.sleep(wait_time)
                    else:
                        logger.error(f"æ‰€æœ‰é‡è¯•å·²ç”¨å°½ï¼Œæœ€ç»ˆå¤±è´¥: {str(e)}")
                        
            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
            raise last_exception or Exception("æœ€å¤§é‡è¯•æ¬¡æ•°å·²ç”¨å°½")
        return wrapper
    return decorator


@async_retry()
async def safe_api_call_async(client, messages, model):
    """å®‰å…¨çš„å¼‚æ­¥APIè°ƒç”¨ï¼Œå†…ç½®é‡è¯•æœºåˆ¶"""
    api_type = "OpenAI" if "gpt" in model.lower() else "DeepSeek"
    
    try:
        logger.info(f"å¼€å§‹è°ƒç”¨{api_type} API, æ¨¡å‹:{model}")
        
        # ä½¿ç”¨ä¼ å…¥å®¢æˆ·ç«¯å‘é€è¯·æ±‚
        response = await client.chat.completions.create(
            model=model,
            response_format={'type': "json_object"},
            messages=messages,
            temperature=0.3,
            top_p=0.7,
            frequency_penalty=0,
            presence_penalty=0,
        )

        # æ£€æŸ¥å“åº”ç»“æ„
        if not hasattr(response, 'choices') or len(response.choices) == 0:
            logger.error(f"æ— æ•ˆçš„APIå“åº”ç»“æ„: {response}")
            raise ValueError("æ— æ•ˆçš„APIå“åº”ç»“æ„")

        message = response.choices[0].message
        if not hasattr(message, 'content'):
            logger.error(f"å“åº”ä¸­ç¼ºå°‘ç¿»è¯‘å†…å®¹: {message}")
            raise ValueError("å“åº”ä¸­ç¼ºå°‘ç¿»è¯‘å†…å®¹")

        # é¢„éªŒè¯JSONæ ¼å¼
        try:
            json_content = json.loads(message.content)
            logger.debug(f"APIè°ƒç”¨æˆåŠŸè¿”å›æœ‰æ•ˆJSON")
        except json.JSONDecodeError as e:
            logger.error(f"JSONé¢„éªŒè¯å¤±è´¥: {message.content}")
            raise

        return response

    except openai.APIConnectionError as e:
        # è®°å½•è¿æ¥é”™è¯¯è¯¦æƒ…
        import traceback
        
        # è·å–é”™è¯¯ä»£ç å’ŒHTTPçŠ¶æ€ç 
        status_code = getattr(e, 'status_code', 'unknown')
        error_code = getattr(e, 'code', 'unknown')
        
        # è·å–åº•å±‚å¼‚å¸¸è¯¦æƒ…
        cause = e.__cause__ if hasattr(e, '__cause__') else None
        cause_type = type(cause).__name__ if cause else 'None'
        cause_str = str(cause) if cause else 'None'
        
        # è¾“å‡ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
        logger.error(f"{api_type} APIè¿æ¥é”™è¯¯è¯¦æƒ…: {str(e)}")
        logger.error(f"çŠ¶æ€ç : {status_code}, é”™è¯¯ç : {error_code}")
        logger.error(f"åº•å±‚å¼‚å¸¸: {cause_type}: {cause_str}")
        logger.error(f"å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
        
        # é‡æ–°æŠ›å‡ºå¼‚å¸¸
        raise
        
    except openai.APITimeoutError as e:
        logger.error(f"{api_type} APIè¶…æ—¶: {str(e)}")
        logger.error(f"è¶…æ—¶è¯¦æƒ…: {traceback.format_exc()}")
        raise
        
    except openai.RateLimitError as e:
        # è®°å½•é™æµé”™è¯¯è¯¦æƒ…
        status_code = getattr(e, 'status_code', 'unknown')
        error_code = getattr(e, 'code', 'unknown')
        
        logger.error(f"{api_type} APIé€Ÿç‡é™åˆ¶: {str(e)}")
        logger.error(f"çŠ¶æ€ç : {status_code}, é”™è¯¯ç : {error_code}")
        raise
        
    except openai.APIResponseValidationError as e:
        # è®°å½•å“åº”éªŒè¯é”™è¯¯è¯¦æƒ…
        status_code = getattr(e, 'status_code', 'unknown')
        error_code = getattr(e, 'code', 'unknown')
        
        logger.error(f"{api_type} APIå“åº”éªŒè¯é”™è¯¯: {str(e)}")
        logger.error(f"çŠ¶æ€ç : {status_code}, é”™è¯¯ç : {error_code}")
        raise
        
    except openai.AuthenticationError as e:
        # è®°å½•éªŒè¯é”™è¯¯è¯¦æƒ…
        status_code = getattr(e, 'status_code', 'unknown')
        error_code = getattr(e, 'code', 'unknown')
        
        logger.error(f"{api_type} APIéªŒè¯é”™è¯¯: {str(e)}")
        logger.error(f"çŠ¶æ€ç : {status_code}, é”™è¯¯ç : {error_code}")
        raise
        
    except openai.BadRequestError as e:
        # è®°å½•è¯·æ±‚é”™è¯¯è¯¦æƒ…
        status_code = getattr(e, 'status_code', 'unknown')
        error_code = getattr(e, 'code', 'unknown')
        param = getattr(e, 'param', 'unknown')
        
        logger.error(f"{api_type} APIè¯·æ±‚é”™è¯¯: {str(e)}")
        logger.error(f"çŠ¶æ€ç : {status_code}, é”™è¯¯ç : {error_code}, å‚æ•°: {param}")
        raise
        
    except Exception as e:
        # è®°å½•å…¶ä»–å¼‚å¸¸
        logger.error(f"å¼‚æ­¥APIè°ƒç”¨å¤±è´¥: {str(e)}")
        logger.error(f"å¼‚å¸¸ç±»å‹: {type(e).__name__}")
        logger.error(f"å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
        raise


def generate_custom_prompt(video_title: str, channel_name: str, custom_prompt: str) -> str:
    """
    æ ¹æ®è§†é¢‘æ ‡é¢˜å’Œé¢‘é“åç”Ÿæˆè‡ªå®šä¹‰æç¤º
    
    å‚æ•°:
        video_title (str): è§†é¢‘æ ‡é¢˜
        channel_name (str): é¢‘é“åç§°
        
    è¿”å›:
        str: æ ¼å¼åŒ–çš„æç¤ºå­—ç¬¦ä¸²
    """
    if custom_prompt:
        full_custom_prompt = f"{custom_prompt}\n\nvideo title: {video_title}\nchannel name: {channel_name}"
    else:
        full_custom_prompt = f"video title: {video_title}\nchannel name: {channel_name}"
    return full_custom_prompt

# 250417æ›´æ–°
async def process_chunk(chunk, custom_prompt, model, client, semaphore, system_prompt_template, video_id="unknown"):
    """å¤„ç†å•ä¸ªç¿»è¯‘æ‰¹æ¬¡"""
    async with semaphore:
        result = {
            'translations': {}
        }
        
        chunk_string = ''.join(f"{number}: {sentence}\n" for number, sentence in chunk)
        check_chunk_string = chunk_string.count('\n')
        first_item_number = chunk[0][0] if chunk else "N/A"
        end_item_number = first_item_number + check_chunk_string - 1
        
        # æ ¼å¼åŒ–ç³»ç»Ÿæç¤ºæ¨¡æ¿
        trans_json_user_prompt = system_prompt_template.format(
            custom_prompt=custom_prompt,
            first_item_number=first_item_number,
            end_item_number=end_item_number,
            check_chunk_string=check_chunk_string
        )
        
        # å‡†å¤‡è°ƒè¯•è®°å½•çš„åŸºç¡€ä¿¡æ¯
        chunk_info = {
            'first': first_item_number,
            'end': end_item_number,
            'expected': check_chunk_string
        }
        input_data = {
            'system_prompt': trans_json_user_prompt,
            'user_content': chunk_string.strip()
        }
        try:
            # åˆæ¬¡APIè°ƒç”¨
            response = await safe_api_call_async(
                client=client,
                messages=[
                    {"role": "system", "content": trans_json_user_prompt},
                    {"role": "user", "content": chunk_string}
                ],
                model=model
            )

            translated_string = response.choices[0].message.content
            
            try:
                trans_to_json = json.loads(translated_string)
            except json.JSONDecodeError as e:
                # JSONè§£æå¤±è´¥çš„è°ƒè¯•è®°å½•
                output_data = {
                    'raw_response': translated_string[:500] + ("..." if len(translated_string) > 500 else ""),
                    'actual_lines': 'JSON_ERROR',
                    'formatted_output': f'JSONè§£æå¤±è´¥: {str(e)}'
                }
                result_info = {
                    'success': False,
                    'line_count_match': False,
                    'error_message': f'JSONè§£æå¤±è´¥: {str(e)}'
                }
                add_debug_record(video_id, chunk_info, input_data, output_data, result_info, "initial")
                raise

            # è¡Œæ•°æ£€æŸ¥
            check_translated = len(trans_to_json)
            
            # æ ¼å¼åŒ–è¾“å‡ºç”¨äºè°ƒè¯•è®°å½•
            formatted_output = '\n'.join(f"{k}: {v}" for k, v in trans_to_json.items())
            
            output_data = {
                'raw_response': translated_string[:500] + ("..." if len(translated_string) > 500 else ""),
                'actual_lines': check_translated,
                'formatted_output': formatted_output
            }
            
            if check_chunk_string == check_translated:
                logger.info(f'ç¼–å·{first_item_number}ä¸€æ¬¡æ€§é€šè¿‡')
                # æˆåŠŸçš„è°ƒè¯•è®°å½•
                result_info = {
                    'success': True,
                    'line_count_match': True,
                    'error_message': 'ä¸€æ¬¡é€šè¿‡'
                }
                add_debug_record(video_id, chunk_info, input_data, output_data, result_info, "initial")
                
                # æ­£å¸¸å¤„ç†æµç¨‹
                new_num_dict = process_transdict_num(trans_to_json, first_item_number, end_item_number)
                translated_dict = process_translated_string(new_num_dict)
                result['translations'].update(translated_dict)
            else:
                # è¿›å…¥é‡è¯•é€»è¾‘ï¼Œå…ˆè®°å½•åˆæ¬¡å¤±è´¥
                result_info = {
                    'success': False,
                    'line_count_match': False,
                    'error_message': f'è¡Œæ•°ä¸åŒ¹é…ï¼Œè¿›å…¥é‡è¯•é€»è¾‘'
                }
                add_debug_record(video_id, chunk_info, input_data, output_data, result_info, "initial")
                
                logger.info(f'ç¼–å·{first_item_number}è¿›å…¥é‡è¯•é€»è¾‘!!!')
                retry_prompt_v2 = f'''
                The previous translation had a mismatch (English: {check_chunk_string} lines, Chinese: {check_translated} lines).

                Please carefully translate each line individually, maintaining a strict one-to-one match between English and Chinese lines (lines {first_item_number}-{end_item_number}, total {check_chunk_string} lines).

                Return your translation in this JSON format:

                {{
                "1": "<Translated line 1>",
                "2": "<Translated line 2>",
                ...
                }}
                '''

                try:
                    # é‡è¯•APIè°ƒç”¨
                    @retry(stop=stop_after_attempt(2))
                    async def retry_call():
                        return await safe_api_call_async(
                            client=client,
                            messages=[
                                {"role": "system", "content": trans_json_user_prompt},
                                {"role": "assistant", "content": translated_string},
                                {"role": "user", "content": retry_prompt_v2}
                            ],
                            model=model
                        )
                        
                    retry_response = await retry_call()
                    
                    retry_translated_string = retry_response.choices[0].message.content

                    # å¼ºåˆ¶é‡å¤éªŒè¯
                    try:
                        retrytrans_to_json = json.loads(retry_translated_string)
                    except json.JSONDecodeError as e:
                        # é‡è¯•JSONè§£æå¤±è´¥çš„è°ƒè¯•è®°å½•
                        retry_output_data = {
                            'raw_response': retry_translated_string[:500] + ("..." if len(retry_translated_string) > 500 else ""),
                            'actual_lines': 'JSON_ERROR',
                            'formatted_output': f'é‡è¯•JSONè§£æå¤±è´¥: {str(e)}'
                        }
                        retry_result_info = {
                            'success': False,
                            'line_count_match': False,
                            'error_message': f'é‡è¯•JSONè§£æå¤±è´¥: {str(e)}'
                        }
                        retry_input_data = {
                            'system_prompt': trans_json_user_prompt,
                            'user_content': retry_prompt_v2.strip()
                        }
                        add_debug_record(video_id, chunk_info, retry_input_data, retry_output_data, retry_result_info, "retry")
                        logger.error(f"é‡è¯•å“åº”JSONè§£æå¤±è´¥: {retry_translated_string}")
                        raise

                    # é‡å¤è¡Œæ•°æ£€æŸ¥
                    check_retry = len(retrytrans_to_json)
                    
                    # å‡†å¤‡é‡è¯•çš„è°ƒè¯•è®°å½•
                    retry_formatted_output = '\n'.join(f"{k}: {v}" for k, v in retrytrans_to_json.items())
                    retry_output_data = {
                        'raw_response': retry_translated_string[:500] + ("..." if len(retry_translated_string) > 500 else ""),
                        'actual_lines': check_retry,
                        'formatted_output': retry_formatted_output
                    }
                    retry_input_data = {
                        'system_prompt': trans_json_user_prompt,
                        'user_content': retry_prompt_v2.strip()
                    }
                    
                    if check_retry == check_chunk_string:
                        # å¤„ç†æˆåŠŸé‡è¯•
                        logger.info(f"ç¼–å·{first_item_number}é‡è¯•æœ‰æ•ˆï¼")
                        
                        # é‡è¯•æˆåŠŸçš„è°ƒè¯•è®°å½•
                        retry_result_info = {
                            'success': True,
                            'line_count_match': True,
                            'error_message': 'é‡è¯•æˆåŠŸ'
                        }
                        add_debug_record(video_id, chunk_info, retry_input_data, retry_output_data, retry_result_info, "retry")
                        
                        # å¯¹ç¿»è¯‘åçš„å­—ç¬¦ä¸²è¿›è¡Œå¤„ç†
                        new_num_dict = process_transdict_num(retrytrans_to_json, first_item_number, end_item_number)
                        translated_dict = process_translated_string(new_num_dict)
                        
                        result['translations'].update(translated_dict)
                    else:
                        # é‡è¯•ä»ç„¶å¤±è´¥çš„è°ƒè¯•è®°å½•
                        retry_result_info = {
                            'success': False,
                            'line_count_match': False,
                            'error_message': f'é‡è¯•åè¡Œæ•°ä»ä¸åŒ¹é… ({check_retry} vs {check_chunk_string})'
                        }
                        add_debug_record(video_id, chunk_info, retry_input_data, retry_output_data, retry_result_info, "retry")
                        raise ValueError(f"ç¼–å·{first_item_number}é‡è¯•åè¡Œæ•°ä»ä¸åŒ¹é… ({check_retry} vs {check_chunk_string})")

                except Exception as retry_error:
                    logger.error(f"é‡è¯•å¤±è´¥: {str(retry_error)}")
                    result['translations'][first_item_number] = f"ç¿»è¯‘å¤±è´¥: {str(retry_error)}"

        except Exception as main_error:
            logger.error(f"ä¸»æµç¨‹é”™è¯¯: {str(main_error)}")
            result['translations'][first_item_number] = f"å…³é”®é”™è¯¯: {str(main_error)}"

        return result


# å¤„ç†ç¿»è¯‘ä¹‹åçš„å­—ç¬¦ä¸²
def process_translated_string(translated_json):
    # å®šä¹‰ç”¨äºåŒ¹é…ä¸­æ–‡æ ‡ç‚¹çš„æ­£åˆ™è¡¨è¾¾å¼
    chinese_punctuation = r"[\u3000-\u303F\uFF01-\uFFEF<>]"

    # é‡æ–°æ„å»ºå¸¦åºå·çš„å¥å­æ ¼å¼
    translated_dict = {}

    for number, sentence in translated_json.items():
        # åˆ é™¤ä¸­æ–‡æ ‡ç‚¹ç¬¦å·
        sentence = re.sub(chinese_punctuation, ' ', sentence)

        number = int(number)
        # æœ€åä¿å­˜æˆå­—å…¸
        translated_dict[number] = sentence
    return translated_dict


# å¤„ç†ç¿»è¯‘ä¹‹åçš„å­—å…¸ç¼–å·ï¼Œé¿å…LLMè¾“å‡ºçš„å­—å…¸ç¼–å·æœ‰è¯¯
def process_transdict_num(input_dict, start_num, end_num):
    processed_dict = {}
    for i, (key, value) in enumerate(input_dict.items(), start=start_num):
        new_key = str(i)
        if i <= end_num:
            processed_dict[new_key] = value
        else:
            break
    return processed_dict


# å°†åŸå§‹è‹±æ–‡å­—å¹•è½¬ä¸ºå­—å…¸
def subtitles_to_dict(subtitles):
    """
    Parse subtitles that include a number, a time range, and text.
    Returns a dictionary with numbers as keys and a tuple (time range, text) as values.
    """
    subtitles_dict = {}
    lines = subtitles.strip().split("\n")
    current_number = None
    current_time_range = ""
    current_text = ""

    for line in lines:
        if line.isdigit():
            if current_number is not None:
                subtitles_dict[current_number] = (current_time_range, current_text.strip())
            current_number = int(line)
        elif '-->' in line:
            current_time_range = line
            current_text = ""
        else:
            current_text += line + " "

    subtitles_dict[current_number] = (current_time_range, current_text.strip())

    return subtitles_dict


# å°†åˆå¹¶åçš„è‹±æ–‡å¥å­ä¸åŸå§‹è‹±æ–‡å­—å¹•åšåŒ¹é…ï¼Œç»™åˆå¹¶åçš„è‹±æ–‡æ·»åŠ ä¸Šæ—¶é—´æˆ³
def map_marged_sentence_to_timeranges(merged_content, subtitles):
    """
    For each merged sentence, find the corresponding subtitles and their time ranges by concatenating
    the subtitles sentences until they match the merged sentence, and merge the time ranges accordingly.
    This version correctly handles multiple merged sentences.
    """
    merged_to_subtitles = {}
    subtitle_index = 0  # Keep track of the current position in the subtitles

    for num, merged_sentence in merged_content.items():
        corresponding_subtitles = []
        start_time = None
        end_time = None
        temp_sentence = ""

        while subtitle_index < len(subtitles):
            sub_num, (time_range, subtitle) = list(subtitles.items())[subtitle_index]
            if start_time is None:
                start_time = time_range.split(' --> ')[0]  # Set the start time of the first subtitle

            temp_sentence += subtitle + " "
            end_time = time_range.split(' --> ')[1]  # Update the end time with each subtitle added
            corresponding_subtitles.append(subtitle)

            # Check if the concatenated subtitles match the merged sentence
            if temp_sentence.strip() == merged_sentence:
                merged_time_range = f"{start_time} --> {end_time}"
                merged_to_subtitles[num] = (merged_time_range, temp_sentence)
                subtitle_index += 1  # Move to the next subtitle for the next iteration
                break

            subtitle_index += 1

    return merged_to_subtitles


# ç»™ä¸­æ–‡ç¿»è¯‘æ·»åŠ æ—¶é—´è½´ï¼Œç”Ÿæˆæœªç»å¥å­é•¿åº¦ä¼˜åŒ–çš„åˆå§‹ä¸­æ–‡å­—å¹•
def map_chinese_to_time_ranges(chinese_content, merged_engsentence_to_subtitles):
    chinese_to_time = {}
    chinese_subtitles = []

    # ä¸å¥å­åˆå¹¶åçš„è‹±æ–‡å­—å¹•åšåŒ¹é…
    for num, chinese_sentence in chinese_content.items():
        if num in merged_engsentence_to_subtitles:
            time_ranges, _ = merged_engsentence_to_subtitles[num]
            chinese_to_time[num] = time_ranges, chinese_sentence

            chinese_subtitles.append([
                num,
                time_ranges,
                chinese_sentence
            ])

    return chinese_to_time

def map_chinese_to_time_ranges_v2(chinese_content, merged_engsentence_to_subtitles):
    """
    ç»™ä¸­æ–‡ç¿»è¯‘æ·»åŠ æ—¶é—´è½´ï¼Œç”Ÿæˆæœªç»å¥å­é•¿åº¦ä¼˜åŒ–çš„åˆå§‹ä¸­æ–‡å­—å¹•ã€‚

    å‚æ•°:
        chinese_content (dict): å­—å…¸ï¼Œkey ä¸ºç¼–å·ï¼Œvalue ä¸ºä¸­æ–‡ç¿»è¯‘å­—ç¬¦ä¸²ã€‚
        merged_engsentence_to_subtitles (dict): å­—å…¸ï¼Œkey ä¸ºç¼–å·ï¼Œvalue ä¸ºä¸€ä¸ªå…ƒç»„ï¼Œæ ¼å¼ä¸º (time_range, subtitle)ã€‚

    è¿”å›:
        dict: key ä¸ºç¼–å·ï¼Œvalue ä¸ºä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹é”®:
              - "time_range": åŸå§‹æ—¶é—´åŒºé—´å­—ç¬¦ä¸²
              - "text": å¯¹åº”çš„ä¸­æ–‡ç¿»è¯‘
    """
    chinese_to_time = {}

    for num, chinese_sentence in chinese_content.items():
        # å¦‚æœå½“å‰ç¼–å·åœ¨è‹±æ–‡å­—å¹•åˆå¹¶ç»“æœä¸­å­˜åœ¨
        if num in merged_engsentence_to_subtitles:
            time_range, _ = merged_engsentence_to_subtitles[num]
            # ç”¨è‡ªæè¿°çš„å­—å…¸ç»“æ„ä¿å­˜ä¿¡æ¯
            chinese_to_time[num] = {
                "time_range": time_range,
                "text": chinese_sentence
            }

    return chinese_to_time


def parse_time(time_str):
    """è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡"""
    return datetime.strptime(time_str, '%H:%M:%S,%f')


def time_to_str(dt):
    """
    å°† datetime å¯¹è±¡æ ¼å¼åŒ–ä¸º SRT å­—å¹•æ—¶é—´æ ¼å¼ï¼šHH:MM:SS,mmm
    """
    return dt.strftime("%H:%M:%S,%f")[:-3]


async def translate_with_deepseek_async(numbered_sentences_chunks, custom_prompt, special_terms="", content_name="", model='deepseek-chat', video_id="unknown"):
    """
    ä½¿ç”¨DeepSeekå¼‚æ­¥å¹¶è¡Œç¿»è¯‘è‹±æ–‡å­—å¹•åˆ°ä¸­æ–‡
    """
    items = list(numbered_sentences_chunks.items())
    total_translated_dict = {}

    # å¤„ç†ç‰¹æ®Šæœ¯è¯­
    if special_terms:
        special_terms = special_terms.rstrip(".")
        special_terms_list = special_terms.split(", ")

    # åˆ›å»ºä¿¡å·é‡
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS)
    
    # åˆ›å»ºå¼‚æ­¥OpenAIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨API_TIMEOUTé…ç½®è¶…æ—¶
    client = AsyncOpenAI(
        api_key=DEEPSEEK_API_KEY, 
        base_url="https://api.deepseek.com",  # ä¿æŒåŸå§‹URL
        timeout=API_TIMEOUT  # ç›´æ¥ä½¿ç”¨API_TIMEOUTé…ç½®è¶…æ—¶
    )

    # åˆ›å»ºæ‰¹æ¬¡å¤„ç†ä»»åŠ¡
    tasks = []
    for i in range(0, len(items), BATCH_SIZE):
        chunk = items[i:i + BATCH_SIZE]
        tasks.append(
            process_chunk(chunk, custom_prompt, model, client, semaphore, "system_prompt_placeholder", video_id)
        )
    
    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # å¤„ç†ç»“æœ
    for result in results:
        if isinstance(result, Exception):
            logger.error(f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {str(result)}")
            continue
        
        # æ›´æ–°ç¿»è¯‘ç»“æœ
        translations = result.get('translations', {})
        total_translated_dict.update(translations)

    logger.info(f'ä½¿ç”¨çš„æ¨¡å‹ï¼š{model}')

    return total_translated_dict

# 050403æ›´æ–°
# ä½¿ç”¨åˆ†å‰²åè¾“å…¥çš„å­—å…¸å†…å®¹
def format_subtitles_v2(subtitles_dict):
    formatted_str = ""
    num_counter = 1  # åˆå§‹åŒ–è®¡æ•°å™¨
    for key in sorted(subtitles_dict.keys()):
        subtitle = subtitles_dict[key]
        formatted_str += f"{num_counter}\n"
        formatted_str += f"{subtitle['time_range']}\n"
        formatted_str += f"{subtitle['text']}\n\n"
        num_counter += 1
    return formatted_str

# 250403æ›´æ–°ï¼šå‘ç°ä¸¤ä¸ªæ²¡æœ‰ç”¨çš„å‡½æ•°
# async def robust_transcribe(file_path, max_attempts=3):
#     """
#     å¸¦æœ‰é‡è¯•æœºåˆ¶çš„éŸ³é¢‘è½¬å†™å‡½æ•°ï¼Œå¤„ç†å„ç§è¶…æ—¶å’Œç½‘ç»œé”™è¯¯ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰
    
#     å‚æ•°:
#         file_path (Path): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
#         max_attempts (int): æœ€å¤§é‡è¯•æ¬¡æ•°
        
#     è¿”å›:
#         dict: è½¬å†™ç»“æœ
#     """
#     # å®šä¹‰å¯ä»¥é‡è¯•çš„å¼‚å¸¸ç±»å‹
#     retriable_exceptions = (
#         httpx.ReadTimeout, 
#         httpx.ConnectTimeout,
#         httpx.ReadError,
#         httpx.NetworkError,
#         ConnectionError,
#         TimeoutError
#     )
    
#     # é‡è¯•è£…é¥°å™¨ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰
#     current_attempt = 0
#     last_exception = None
    
#     while current_attempt < max_attempts:
#         try:
#             logger.info(f"å¼€å§‹è½¬å†™å°è¯• {current_attempt+1}/{max_attempts}...")
#             return await transcribe_audio(file_path)
#         except retriable_exceptions as e:
#             current_attempt += 1
#             last_exception = e
#             wait_time = min(2 ** current_attempt, 60)  # æŒ‡æ•°é€€é¿
#             logger.info(f"ç¬¬ {current_attempt}/{max_attempts} æ¬¡å°è¯•å¤±è´¥ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
#             await asyncio.sleep(wait_time)
#         except Exception as e:
#             # éé‡è¯•ç±»å‹å¼‚å¸¸ï¼Œç›´æ¥æŠ›å‡º
#             logger.error(f"è½¬å†™å¤±è´¥ï¼Œé‡åˆ°éé‡è¯•ç±»å‹å¼‚å¸¸: {str(e)}", exc_info=True)
#             raise
    
#     # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥
#     logger.error(f"æ‰€æœ‰è½¬å†™å°è¯•å‡å¤±è´¥: {str(last_exception)}", exc_info=True)
#     # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…å¤„ç†
#     raise last_exception or Exception("æœ€å¤§é‡è¯•æ¬¡æ•°å·²ç”¨å°½")

# 250403æ›´æ–°ï¼šå‘ç°ä¸¤ä¸ªæ²¡æœ‰ç”¨çš„å‡½æ•°
# ä¿®æ”¹å¤„ç†éŸ³é¢‘æ¥å£çš„è°ƒç”¨æ–¹å¼
# async def process_audio(audio_path, output_dir, content_name, custom_prompt="", special_terms=""):
#     """
#     å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼ŒåŒ…æ‹¬è½¬å†™å’Œç¿»è¯‘
    
#     å‚æ•°:
#         audio_path (Path): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
#         output_dir (Path): è¾“å‡ºç›®å½•
#         content_name (str): å†…å®¹åç§°
#         custom_prompt (str): è‡ªå®šä¹‰æç¤º
#         special_terms (str): ç‰¹æ®Šæœ¯è¯­
        
#     è¿”å›:
#         dict: å¤„ç†ç»“æœ
#     """
#     try:
#         # ä½¿ç”¨å¸¦é‡è¯•åŠŸèƒ½çš„è½¬å†™å‡½æ•°
#         transcription = await robust_transcribe(audio_path, max_attempts=3)
                
#         # ç»§ç»­åç»­å¤„ç†...
#         # ...
        
#         # åç»­ä»£ç ä¿æŒä¸å˜
#         # ...
        
#     except Exception as e:
#         logger.error(f"å¤„ç†éŸ³é¢‘å¤±è´¥: {str(e)}", exc_info=True)
#         raise 


#async def split_long_chinese_sentence_v3(chinese_timeranges_dict, model='deepseek-chat'):
#     '''
#     v3ç‰ˆæœ¬ï¼Œå…ˆæŠŠä¸­æ–‡å¥å­æŒ‰ç…§ç©ºæ ¼è¿›è¡Œåˆ†å‰²ï¼Œç„¶åå†å¯¹è¶…è¿‡40ä¸ªå­—çš„é•¿å¥å­è¿›è¡Œåˆ†å‰²
#     '''
#     # å…ˆæŒ‰ç…§ç©ºæ ¼åˆ†å‰²
#     space_split_subtitles = {}
#     space_split_index = 1

#     for index, (time_range, text) in chinese_timeranges_dict.items():
#         start_time, end_time = time_range.split(' --> ')
#         # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²ä¸­æ–‡å¥å­ä¹‹é—´çš„ç©ºæ ¼
#         parts = re.split(r'(?<=[\u4e00-\u9fff])\s+(?=[\u4e00-\u9fff])', text)
#         num_parts = len(parts)
#         total_length = sum(len(part) for part in parts)

#         if num_parts > 1:
#             start_time = parse_time(start_time)
#             end_time = parse_time(end_time)
#             word_per_duration = (end_time - start_time)/total_length
#             current_start_time = start_time

#             for i, part in enumerate(parts):
#                 current_end_time = current_start_time + word_per_duration * len(part)
#                 space_split_subtitles[space_split_index] = (f"{time_to_str(current_start_time)} --> {time_to_str(current_end_time)}", part)
#                 current_start_time = current_end_time
#                 space_split_index += 1
#         else:
#             space_split_subtitles[space_split_index] = (time_range, text)
#             space_split_index += 1

#     # å¤åˆ¶å­—å…¸
#     split_subtitles_dict = space_split_subtitles.copy()

#     # æ‰¾å‡ºä¸­æ–‡å­—å¹•ä¸­çš„é•¿å­—å¹•
#     threshold = 40
#     long_subtitles = []
#     for key, (timeranges, subtitles) in space_split_subtitles.items():
#         if len(subtitles) > threshold:
#             long_subtitles.append((key, timeranges, subtitles))

#     # å¯¹é•¿å­—å¹•å¼€å§‹è¿›è¡Œä¼˜åŒ–
#     # å¾ªç¯æ§åˆ¶
#     for key, timeranges, subtitles in long_subtitles:
#         # åœ¨å¾ªç¯ä¸­æå–æ—¶é—´èŒƒå›´
#         start_str, end_str = timeranges.split(' --> ')
#         start_time = parse_time(start_str)
#         end_time = parse_time(end_str)

#         # åœ¨å¾ªç¯ä¸­è°ƒç”¨apiåˆ†å‰²å¥å­
#         # apiè°ƒç”¨ï¼Œè¿”å›api_return_content
#         split_prompt_v2 = f'''
#         Split the long Chinese sentences below, delimited by triple backtick
#         - Only split long sentences, do not alter the content of the sentences
#         - According to your understanding of the sentence, divide the long sentence into several short sentences that are easiest to understand.
#         - When splitting, please keep the "linguistic integrity" together.
#         - Each short sentence should not exceed 20 Chinese characters as much as possible.

#         Provide your translation in json structure like this:{{
#               '1':'<Segmented short sentences 1>',
#               '2':'<Segmented short sentences 2>',
#               }}
#         long Chinese sentences below: ```{subtitles}```
#         '''
        
#         logger.info(f"å¯¹é•¿å¥å­è¿›è¡Œåˆ†å‰²: {subtitles}")
        
#         client = AsyncOpenAI(
#             api_key=DEEPSEEK_API_KEY, 
#             base_url="https://api.deepseek.com",
#             timeout=float(API_TIMEOUT)
#         )
        
#         messages = [
#             {"role": "user", "content": split_prompt_v2},
#         ]
        
#         # è°ƒç”¨APIåˆ†å‰²é•¿å¥å­
#         try:
#             response = await client.chat.completions.create(
#                 model=model,
#                 response_format={'type': "json_object"},
#                 messages=messages,
#                 temperature=0,
#                 top_p=1,
#                 frequency_penalty=0,
#                 presence_penalty=0,
#             )
#             api_return_content = response.choices[0].message.content
            
#             # å¤„ç†apiè¿”å›çš„jsonç»“æœï¼Œè½¬ä¸ºå­—å…¸
#             api_return_content_todict = json.loads(api_return_content)
#             all_text = ''.join(api_return_content_todict.values())
            
#             # åœ¨å¾ªç¯ä¸­å®ŒæˆçŸ­å¥çš„æ—¶é—´è½´è®¡ç®—å’ŒåŒ¹é…
#             # æ–°å»ºä¸€ä¸ªåˆ—è¡¨ç”¨æ¥å­˜å‚¨åˆ†å‰²åçš„å­—å¹•ä¿¡æ¯
#             split_subtitles = []
#             # è®¡ç®—æ€»æ—¶é•¿
#             duration = (end_time - start_time).total_seconds()
#             # ç”¨è¿”å›çš„å¥å­æ¥è®¡ç®—æ¯ä¸ªå­—ç¬¦çš„æŒç»­æ—¶é—´
#             word_duration = duration / len(all_text)
#             # èµ·å§‹æ—¶é—´
#             current_start_time = start_time
#             # ä¸ºåˆ†å‰²åçš„æ¯ä¸ªå­—å¹•ç”Ÿæˆæ—¶é—´è½´
#             short_subtitle_list = list(api_return_content_todict.values())
#             for short_subtitle in short_subtitle_list:
#                 # è®¡ç®—æ—¶é—´è½´ä¿¡æ¯
#                 short_subtitle_duration = len(short_subtitle) * word_duration
#                 current_end_time = current_start_time + timedelta(seconds=short_subtitle_duration)
#                 # å­˜å‚¨åˆ†å‰²åå­—å¹•çš„æ—¶é—´è½´
#                 short_subtitle_time_range = f'{time_to_str(current_start_time)} --> {time_to_str(current_end_time)}'
#                 split_subtitles.append((short_subtitle_time_range, short_subtitle))
#                 # æ›´æ–°åˆå§‹æ—¶é—´
#                 current_start_time = current_end_time
            
#             # åœ¨å¾ªç¯ä¸­æ›´æ–°split_subtitles_dictå­—å…¸
#             split_subtitles_dict[key] = split_subtitles
            
#         except Exception as e:
#             logger.error(f"é•¿å¥åˆ†å‰²å¤±è´¥: {str(e)}", exc_info=True)
#             # å¦‚æœåˆ†å‰²å¤±è´¥ï¼Œä¿ç•™åŸå§‹å¥å­
#             split_subtitles_dict[key] = [(timeranges, subtitles)]

#     logger.info(f'ä½¿ç”¨çš„æ¨¡å‹ï¼š{model}')
    
#     # å¤„ç†æœ€ç»ˆçš„å­—å…¸ç»“æ„ï¼Œä½¿å…¶ç¬¦åˆé¢„æœŸçš„æ ¼å¼
#     final_dict = {}
#     current_index = 1
    
#     for key, value in split_subtitles_dict.items():
#         if isinstance(value, list):  # å¤„ç†è¢«åˆ†å‰²çš„å­—å¹•
#             for time_range, text in value:
#                 final_dict[current_index] = (time_range, text)
#                 current_index += 1
#         else:  # å¤„ç†æœªè¢«åˆ†å‰²çš„å­—å¹•
#             time_range, text = value
#             final_dict[current_index] = (time_range, text)
#             current_index += 1
    
#     logger.info(f"é•¿å¥å­æ‹†åˆ†å®Œæˆï¼šåŸå§‹{len(chinese_timeranges_dict)}ä¸ªæ¡ç›®ï¼Œæ‹†åˆ†å{len(final_dict)}ä¸ªæ¡ç›®")
#     return final_dict 

# 250403æ›´æ–°
# å…¨æ–°çš„é•¿å¥åˆ†å‰²æ–¹æ³•ã€‚å¯¹äºæ— æ³•æŒ‰ç…§è§„åˆ™åˆ†å‰²çš„å¥å­ï¼Œè°ƒç”¨å¼‚æ­¥LLMåˆ†å‰²
def time_to_str(dt):
    """
    å°† datetime å¯¹è±¡æ ¼å¼åŒ–ä¸º SRT å­—å¹•æ—¶é—´æ ¼å¼ï¼šHH:MM:SS,mmm
    """
    return dt.strftime("%H:%M:%S,%f")[:-3]

def parse_time_range(time_range_str):
    """
    è§£æå½¢å¦‚ "HH:MM:SS,mmm --> HH:MM:SS,mmm" çš„æ—¶é—´åŒºé—´å­—ç¬¦ä¸²ï¼Œ
    è¿”å›èµ·å§‹æ—¶é—´å’Œç»“æŸæ—¶é—´å¯¹åº”çš„ datetime å¯¹è±¡ã€‚
    æ­¤å¤„ä»¥ 1900-01-01 ä¸ºåŸºç¡€æ—¥æœŸã€‚
    """
    try:
        start_str, end_str = time_range_str.split(" --> ")
        base_date = datetime.date(1900, 1, 1)
        start_dt = datetime.datetime.strptime(f"{base_date} {start_str}", "%Y-%m-%d %H:%M:%S,%f")
        end_dt = datetime.datetime.strptime(f"{base_date} {end_str}", "%Y-%m-%d %H:%M:%S,%f")
        return start_dt, end_dt
    except Exception as e:
        logger.error(f"è§£ææ—¶é—´èŒƒå›´é”™è¯¯: {time_range_str}, é”™è¯¯: {str(e)}")
        raise

def split_sentence(text):
    """
    å¯¹è¾“å…¥çš„ä¸­æ–‡å¥å­è¿›è¡Œåˆ†å‰²ï¼š
    1. åªæœ‰é•¿åº¦å¤§äº20ä¸ªå­—ç¬¦çš„å¥å­æ‰è¿›è¡Œåˆ†å‰²ï¼ˆæ­£å¥½20ä¸ªå­—ç¬¦çš„ä¸å¤„ç†ï¼‰ï¼›
    2. ä»¥ç©ºæ ¼ä¸ºåˆ†å‰²æ ‡å¿—ï¼Œä½†ä»…å½“ç©ºæ ¼ä¸¤è¾¹éƒ½æ˜¯ä¸­æ–‡å­—ç¬¦æ—¶è¿›è¡Œåˆ†å‰²ï¼›
    3. åˆ†å‰²åæ¯ä¸€éƒ¨åˆ†å¿…é¡»è‡³å°‘æœ‰5ä¸ªå­—ç¬¦ï¼ˆå…è®¸æ°å¥½5ä¸ªå­—ç¬¦ï¼‰ï¼›
    4. å¯¹é•¿å¥å­é‡‡ç”¨é€’å½’æ–¹å¼å¤„ç†æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„åˆ†å‰²ç‚¹ã€‚
    """
    if len(text) <= 20:
        return [text]

    # pattern = re.compile(
    # r'(?<=[\u4e00-\u9fff])\s+(?=[A-Za-z0-9\u4e00-\u9fff])'
    # r'|(?<=[A-Za-z0-9])\s+(?=[\u4e00-\u9fff])')
    #250506 ä¿®æ”¹åˆ†å‰²è§„åˆ™ï¼Œåªåˆ†å‰²ä¸­æ–‡å­—ç¬¦ä¹‹é—´çš„ç©ºæ ¼
    pattern = re.compile(r'(?<=[\u4e00-\u9fff])\s+(?=[\u4e00-\u9fff])')
    matches = list(pattern.finditer(text))

    for match in matches:
        left = text[:match.start()]
        right = text[match.end():]
        if len(left) >= 6 and len(right) >= 6:
            return [left] + split_sentence(right)

    return [text]

def assign_time_ranges(start_time, end_time, segments):
    """
    æ ¹æ®èµ·å§‹æ—¶é—´ã€ç»“æŸæ—¶é—´å’Œæ–‡æœ¬ç‰‡æ®µåˆ—è¡¨ï¼Œè®¡ç®—æ¯ä¸ªç‰‡æ®µå¯¹åº”çš„æ—¶é—´åŒºé—´ã€‚
    è¿”å›åˆ—è¡¨ä¸­æ¯ä¸ªå…ƒç´ ä¸ºå…ƒç»„ï¼š(èµ·å§‹æ—¶é—´å­—ç¬¦ä¸², ç»“æŸæ—¶é—´å­—ç¬¦ä¸², æ–‡æœ¬ç‰‡æ®µ)
    """
    total_duration = (end_time - start_time).total_seconds()
    total_chars = sum(len(seg) for seg in segments)
    
    if total_chars == 0:
        logger.warning("åˆ†é…æ—¶é—´åŒºé—´æ—¶å‘ç°æ€»å­—ç¬¦æ•°ä¸ºé›¶ï¼Œè¿”å›ç©ºåˆ—è¡¨")
        return []
    per_char_duration = total_duration / total_chars

    assigned_ranges = []
    current_time = start_time
    for seg in segments:
        seg_duration = len(seg) * per_char_duration
        new_end = current_time + datetime.timedelta(seconds=seg_duration)
        assigned_ranges.append((time_to_str(current_time), time_to_str(new_end), seg))
        current_time = new_end
    return assigned_ranges

async def split_long_chinese_sentence_v4(chinese_timeranges_dict):
    """
    å¤„ç† chinese_timeranges_dict ä¸­çš„é•¿æ–‡æœ¬ï¼Œåˆ†ä¸¤ä¸ªé˜¶æ®µï¼š

    ç¬¬ä¸€é˜¶æ®µï¼šåˆæ­¥å¤„ç†
      - ä½¿ç”¨ split_sentence å’Œ assign_time_ranges å¯¹æ¯æ¡å­—å¹•è¿›è¡Œåˆ†å‰²ï¼Œ
      - ç”Ÿæˆåˆæ­¥å­—å¹•å­—å…¸ initial_subtitlesã€‚

    ç¬¬äºŒé˜¶æ®µï¼šæ‰¹é‡è¿›ä¸€æ­¥å¤„ç†
      - ç­›é€‰å‡ºåˆæ­¥å­—å¹•å­—å…¸ä¸­éœ€è¦è¿›ä¸€æ­¥åˆ†å‰²çš„æ¡ç›®ï¼ˆæ–‡æœ¬é•¿åº¦å¤§äº25ï¼‰ï¼›
      - æ‰¹é‡è°ƒç”¨ LLM åˆ†å‰²æ¥å£ï¼ˆbatch_llm_processï¼Œå ä½ç¬¦å®ç°ï¼‰ï¼Œ
      - å¯¹äºæ¯ä¸ªéœ€è¦å¤„ç†çš„æ¡ç›®ï¼Œä¾æ®å…¶åŸå§‹æ—¶é—´åŒºé—´é‡æ–°è®¡ç®—åˆ†å‰²åçš„å¤šä¸ªç‰‡æ®µå¯¹åº”çš„æ—¶é—´åŒºé—´ï¼Œ
      - å°†åŸæ¡ç›®æ‹†åˆ†ä¸ºå¤šæ¡æ–°çš„å­—å¹•ï¼Œç”Ÿæˆæœ€ç»ˆå­—å¹•å­—å…¸ã€‚
    """
    logger.info(f"å¼€å§‹æ‰§è¡Œé•¿å¥åˆ†å‰²(v4)ï¼Œè¾“å…¥å­—å…¸å¤§å°: {len(chinese_timeranges_dict)}æ¡")
    
    # ç¬¬ä¸€é˜¶æ®µï¼šåˆæ­¥å¤„ç†
    logger.info("ç¬¬ä¸€é˜¶æ®µï¼šä½¿ç”¨è§„åˆ™åˆ†å‰²å’Œæ—¶é—´åŒºé—´åˆ†é…")
    initial_subtitles = {}
    new_index = 1
    
    phase1_split_count = 0  # è®°å½•ç¬¬ä¸€é˜¶æ®µåˆ†å‰²çš„æ•°é‡
    
    for key, item in chinese_timeranges_dict.items():
        time_range = item[0] if isinstance(item, tuple) else item.get("time_range")
        text = item[1] if isinstance(item, tuple) else item.get("text", "")
        
        logger.debug(f"å¤„ç†å­—å¹• #{key}: '{text[:30]}{'...' if len(text) > 30 else ''}', æ—¶é—´èŒƒå›´: {time_range}")
        
        try:
            start_dt, end_dt = parse_time_range(time_range)
            segments = split_sentence(text)
            
            if len(segments) > 1:
                phase1_split_count += 1
                logger.debug(f"å­—å¹• #{key} è¢«è§„åˆ™åˆ†å‰²ä¸º {len(segments)} æ®µ")
            
            assigned_segments = assign_time_ranges(start_dt, end_dt, segments)
            
            for start_time_str, end_time_str, seg_text in assigned_segments:
                initial_subtitles[new_index] = {
                    "time_range": f"{start_time_str} --> {end_time_str}",
                    "text": seg_text
                }
                new_index += 1
        except Exception as e:
            logger.error(f"å¤„ç†å­—å¹• #{key} æ—¶å‡ºé”™: {str(e)}")
            # ä¿ç•™åŸå§‹å­—å¹•ï¼Œé¿å…ä¸¢å¤±å†…å®¹
            initial_subtitles[new_index] = {
                "time_range": time_range,
                "text": text
            }
            new_index += 1

    logger.info(f"ç¬¬ä¸€é˜¶æ®µå®Œæˆ: å¤„ç† {len(chinese_timeranges_dict)} æ¡å­—å¹•ï¼Œé€šè¿‡è§„åˆ™åˆ†å‰²äº† {phase1_split_count} æ¡ï¼Œç”Ÿæˆ {len(initial_subtitles)} æ¡åˆæ­¥å­—å¹•")

    # ç¬¬äºŒé˜¶æ®µï¼šæ‰¹é‡å¤„ç†éœ€è¦è¿›ä¸€æ­¥åˆ†å‰²çš„å­—å¹•
    logger.info("ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨LLMè¿›ä¸€æ­¥åˆ†å‰²é•¿å¥å­")
    keys_to_process = []
    texts_to_process = []
    
    # è¿™é‡Œä»¥æ–‡æœ¬é•¿åº¦å¤§äº20ä½œä¸ºéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²çš„æ¡ä»¶
    for key, value in initial_subtitles.items():
        if len(value["text"]) > 20:
            keys_to_process.append(key)
            texts_to_process.append(value["text"])
    
    logger.info(f"éœ€è¦é€šè¿‡LLMè¿›ä¸€æ­¥åˆ†å‰²çš„å­—å¹•: {len(keys_to_process)} æ¡")
    
    if texts_to_process:
        try:
            texts_to_llm = {str(i+1): text for i, text in enumerate(texts_to_process)}
            logger.info(f"å¼€å§‹è°ƒç”¨LLMæ‰¹é‡åˆ†å‰²é•¿å¥ï¼Œå…± {len(texts_to_llm)} æ¡")
            
            llm_results = await llm_batches_split(texts_to_llm)
            logger.info(f"LLMåˆ†å‰²å®Œæˆï¼Œè¿”å› {len(llm_results.get('results', []))} æ¡ç»“æœ")
            
            # æ„å»ºæœ€ç»ˆçš„å­—å¹•å­—å…¸ï¼Œæ‹†åˆ†åçš„å¤šæ¡å­—å¹•éœ€è¦é‡æ–°è®¡ç®—æ—¶é—´åŒºé—´
            final_subtitles = {}
            final_index = 1
            llm_split_count = 0  # è®°å½•LLMæˆåŠŸåˆ†å‰²çš„æ¡ç›®æ•°
            
            # éå†åˆæ­¥å­—å¹•å­—å…¸ï¼Œå¯¹éœ€è¦è¿›ä¸€æ­¥å¤„ç†çš„æ¡ç›®åšå¤„ç†
            for key, value in initial_subtitles.items():
                if key in keys_to_process:
                    # ä»å½“å‰å­—å¹•ä¸­è·å–åŸå§‹æ–‡æœ¬
                    original_text = value["text"]
                    # é€šè¿‡åŒ¹é… "original" å­—æ®µæŸ¥æ‰¾å¯¹åº”çš„ LLM å¤„ç†ç»“æœ
                    matched_result = None
                    for result in llm_results.get("results", []):
                        if result.get("original") == original_text:
                            matched_result = result
                            break
                    
                    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡æœ¬ä½œä¸ºå”¯ä¸€åˆ†å‰²é¡¹
                    if matched_result is None:
                        logger.warning(f"æœªæ‰¾åˆ°å­—å¹• #{key} çš„LLMåˆ†å‰²ç»“æœï¼Œä¿æŒåŸæ ·: '{original_text[:30]}{'...' if len(original_text) > 30 else ''}'")
                        segmented_texts = [original_text]
                    else:
                        segmented_texts = matched_result.get("segmented", [original_text])
                        if len(segmented_texts) > 1:
                            llm_split_count += 1
                            logger.debug(f"å­—å¹• #{key} è¢«LLMåˆ†å‰²ä¸º {len(segmented_texts)} æ®µ")

                    # ä½¿ç”¨åŸå§‹æ—¶é—´åŒºé—´é‡æ–°åˆ†é…æ–°çš„æ—¶é—´
                    try:
                        original_time_range = value["time_range"]
                        start_dt, end_dt = parse_time_range(original_time_range)
                        new_assigned_segments = assign_time_ranges(start_dt, end_dt, segmented_texts)
                        
                        for start_time_str, end_time_str, seg_text in new_assigned_segments:
                            final_subtitles[final_index] = {
                                "time_range": f"{start_time_str} --> {end_time_str}",
                                "text": seg_text
                            }
                            final_index += 1
                    except Exception as e:
                        logger.error(f"å¤„ç†LLMåˆ†å‰²ç»“æœæ—¶å‘ç”Ÿé”™è¯¯ (å­—å¹• #{key}): {str(e)}")
                        # ä¿ç•™åŸå§‹å­—å¹•ä½œä¸ºå›é€€é€‰é¡¹
                        final_subtitles[final_index] = value
                        final_index += 1
                else:
                    final_subtitles[final_index] = value
                    final_index += 1
            
            logger.info(f"LLMæˆåŠŸåˆ†å‰²äº† {llm_split_count}/{len(keys_to_process)} æ¡å­—å¹•")
            initial_subtitles = final_subtitles
            
        except Exception as e:
            logger.error(f"LLMæ‰¹é‡åˆ†å‰²è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            # å‡ºé”™æ—¶ä¿ç•™ç¬¬ä¸€é˜¶æ®µçš„ç»“æœ
            logger.warning("ç”±äºLLMåˆ†å‰²é”™è¯¯ï¼Œä¿ç•™ç¬¬ä¸€é˜¶æ®µçš„åˆ†å‰²ç»“æœ")

    logger.info(f"é•¿å¥åˆ†å‰²(v4)å®Œæˆ: è¾“å…¥ {len(chinese_timeranges_dict)} æ¡å­—å¹•ï¼Œè¾“å‡º {len(initial_subtitles)} æ¡åˆ†å‰²åçš„å­—å¹•")
    return initial_subtitles

# 250403æ›´æ–°
# å¼‚æ­¥LLMåˆ†å‰²ç›¸å…³å‡½æ•°
# é€šç”¨çš„å¼‚æ­¥é‡è¯•è£…é¥°å™¨
def async_retry(max_attempts=None, exceptions=None):
    """å¼‚æ­¥å‡½æ•°çš„é‡è¯•è£…é¥°å™¨"""
    if max_attempts is None:
        max_attempts = RETRY_ATTEMPTS  # æ›¿æ¢ä¸ºç›´æ¥ä½¿ç”¨RETRY_ATTEMPTSé…ç½®ï¼Œè€Œä¸æ˜¯CONFIGå­—å…¸
    if exceptions is None:
        exceptions = (aiohttp.ClientError, json.JSONDecodeError, Exception)  # ä¿®æ”¹ä¸ºåˆé€‚çš„å¼‚å¸¸ç±»å‹
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    # æŒ‡æ•°é€€é¿ç­–ç•¥
                    wait_time = min(1 * (2 ** attempt), 8)  # ä½¿ç”¨å›ºå®šçš„é€€é¿ç­–ç•¥å‚æ•°
                    logger.warning(f"å°è¯• {attempt+1}/{max_attempts} å¤±è´¥: {str(e)}ï¼Œç­‰å¾… {wait_time}ç§’åé‡è¯•")
                    await asyncio.sleep(wait_time)
            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
            logger.error(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° {max_attempts}ï¼Œæœ€åé”™è¯¯: {str(last_exception)}")
            raise last_exception or Exception("æœ€å¤§é‡è¯•æ¬¡æ•°å·²ç”¨å°½")
        return wrapper
    return decorator

async def llm_batches_split(long_sentences, model='gpt-4.1-mini'):
    """
    ä½¿ç”¨LLMåˆ†å‰²é•¿å¥å­,åˆ›å»ºå¼‚æ­¥ä»»åŠ¡

    å‚æ•°ï¼š
    long_sentences: éœ€è¦åˆ†å‰²çš„é•¿å¥å­å­—å…¸
    model: ä½¿ç”¨çš„æ¨¡å‹åç§°

    è¿”å›ï¼š
    dict:åˆ†å‰²ç»“æœå­—å…¸,æ ¼å¼ä¸º
    {
    "results": [
        {"original": åŸå¥1, "segmented": [å¥å­1, å¥å­2]},
        {"original": åŸå¥2, "segmented": [å¥å­1, å¥å­2]}
    ]
    }
    """
    logger.info(f"å¼€å§‹ä½¿ç”¨LLMæ‰¹é‡åˆ†å‰²é•¿å¥, ä½¿ç”¨æ¨¡å‹: {model}, è¾“å…¥å¥å­æ•°: {len(long_sentences)}")
    
    total_segment_dict = {
        'results':[]
    }
    items = list(long_sentences.items())

    # åˆ›å»ºé”å’Œä¿¡å·é‡
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS)  # ä½¿ç”¨MAX_CONCURRENT_TASKSé…ç½®

    # åˆ›å»ºå¼‚æ­¥OpenAIå®¢æˆ·ç«¯
    client = AsyncOpenAI(
        api_key=OPENAI_API_KEY,
        #base_url="https://api.deepseek.com"
    )

    # åˆ›å»ºæ‰¹æ¬¡å¤„ç†ä»»åŠ¡
    tasks = []
    for i in range(0, len(items), BATCH_SIZE):  # ä½¿ç”¨å¯¼å…¥çš„BATCH_SIZE
        chunk = items[i:i + BATCH_SIZE]
        tasks.append(
            split_process_chunk(chunk, model, client, semaphore)
        )
    
    logger.info(f"åˆ›å»ºäº† {len(tasks)} ä¸ªå¹¶è¡Œä»»åŠ¡è¿›è¡Œé•¿å¥åˆ†å‰²")

    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # å¤„ç†ç»“æœ
    success_count = 0
    for result in results:
        if isinstance(result, Exception):
            logger.error(f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {str(result)}")
            continue
        
        # æ›´æ–°åˆ†å‰²ç»“æœ
        if 'results' in result:
            total_segment_dict['results'].extend(result.get('results',[]))
            success_count += 1

    logger.info(f"LLMæ‰¹é‡åˆ†å‰²å®Œæˆ: {success_count}/{len(tasks)} æ‰¹æ¬¡æˆåŠŸ, å…±å¤„ç† {len(total_segment_dict['results'])} æ¡å¥å­")
    return total_segment_dict

@async_retry()
async def split_safe_api_call_async(client, messages, model, temperature, top_p, frequency_penalty, presence_penalty):
    """å®‰å…¨çš„å¼‚æ­¥APIè°ƒç”¨,å†…ç½®é‡è¯•æœºåˆ¶"""
    try:
        response = await client.chat.completions.create(
            model=model,
            response_format={'type': "json_object"},
            messages=messages,
            temperature=temperature,
            top_p=top_p,
            frequency_penalty=frequency_penalty,
            presence_penalty=presence_penalty,
        )

        # æ£€æŸ¥å“åº”ç»“æ„
        if not hasattr(response, 'choices') or len(response.choices) == 0:
            logger.error("APIå“åº”ç¼ºå°‘choiceså­—æ®µ")
            raise ValueError("æ— æ•ˆçš„APIå“åº”ç»“æ„")

        message = response.choices[0].message
        if not hasattr(message, 'content'):
            logger.error("APIå“åº”ç¼ºå°‘contentå­—æ®µ")
            raise ValueError("å“åº”ä¸­ç¼ºå°‘ç¿»è¯‘å†…å®¹")

        # é¢„éªŒè¯JSONæ ¼å¼
        try:
            json.loads(message.content)
        except json.JSONDecodeError as e:
            logger.error(f"JSONé¢„éªŒè¯å¤±è´¥: {message.content[:100]}...")
            raise

        return response

    except openai.APIConnectionError as e:
        logger.error(f"APIè¿æ¥é”™è¯¯: {str(e)}")
        raise
    except openai.APITimeoutError as e:
        logger.error(f"APIè¶…æ—¶é”™è¯¯: {str(e)}")
        raise
    except openai.RateLimitError as e:
        logger.error(f"APIé€Ÿç‡é™åˆ¶é”™è¯¯: {str(e)}")
        raise
    except Exception as e:
        logger.error(f"å¼‚æ­¥APIè°ƒç”¨å¤±è´¥: {str(e)}")
        raise

async def split_process_chunk(chunk, model, client, semaphore):
    """
    å¤„ç†å•ä¸ªåˆ†å‰²æ‰¹æ¬¡
    """
    async with semaphore:
        logger.debug(f"å¼€å§‹å¤„ç†æ‰¹æ¬¡, åŒ…å« {len(chunk)} æ¡å¥å­")
        result = {'results': []}

        chunk_str = json.dumps(chunk, ensure_ascii=False)
        logger.debug(f"æ‰¹æ¬¡æ•°æ®æ ·æœ¬: {chunk_str[:100]}...")
        
        segment_prompt = f'''
                        è¯·æŒ‰ä»¥ä¸‹è§„åˆ™å¤„ç†ä¸‰é‡åå¼•å·å†…çš„ä¸­æ–‡é•¿å¥é›†åˆï¼š
                        1. è¾“å…¥æ ¼å¼ç¤ºä¾‹ï¼š
                        {{"1":"å¥å­1",
                        "2":"å¥å­2"}}

                        2. æ™ºèƒ½åˆ†å‰²ï¼š
                        - åªæ‹†åˆ†é•¿å¥ï¼Œä¸è¦æ”¹å˜å¥å­çš„å†…å®¹
                        - åˆ†å‰²æ—¶ï¼Œè¯·ä¿æŒ"è¯­è¨€å®Œæ•´æ€§"
                        - ä¼˜å…ˆåœ¨ç©ºæ ¼å¤„æ‹†åˆ†ï¼Œä¿æŒæœ¯è¯­å®Œæ•´ï¼ˆå¦‚"NASA"ã€"5G NR"ï¼‰
                        - æ¯çŸ­å¥10-15ä¸ªå­—ç¬¦ï¼Œæœ€å¤šä¸è¦è¶…è¿‡20ä¸ªå­—ç¬¦
                        3. ä½¿ç”¨jsonæ ¼å¼è¾“å‡ºï¼š
                        {{
                        "results": [
                            {{
                            "original": "åŸå¥1",
                            "segmented": ["çŸ­å¥1", "çŸ­å¥2"]
                            }},
                            {{
                            "original": "åŸå¥2",
                            "segmented": ["çŸ­å¥1", "çŸ­å¥2"]
                            }}
                        ],
                        }}

                        éœ€è¦å¤„ç†çš„é•¿å¥ï¼š```{chunk_str}```
                        '''

    response = await split_safe_api_call_async(
        client=client,
        messages=[
            {"role": "user", "content": segment_prompt}
        ],
        model=model,
        temperature=0,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
    )

    segment_results = response.choices[0].message.content
    result_to_json = json.loads(segment_results)
    result.update(result_to_json)

    return result

# 250403æ›´æ–°
async def translate_subtitles(numbered_sentences_chunks, custom_prompt, model_choice="gpt", special_terms="", content_name="", video_id="unknown"):
    """
    ç»Ÿä¸€çš„å­—å¹•ç¿»è¯‘å‡½æ•°ï¼Œæ”¯æŒä¸åŒæ¨¡å‹é€‰æ‹©
    
    Args:
        numbered_sentences_chunks: ç¼–å·çš„å¥å­å—
        custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
        model_choice: æ¨¡å‹é€‰æ‹©ï¼Œå¯é€‰å€¼ä¸º "deepseek" æˆ– "gpt"
        special_terms: ç‰¹æ®Šæœ¯è¯­åˆ—è¡¨
        content_name: å†…å®¹åç§°
    
    Returns:
        ç¿»è¯‘åçš„å­—å…¸
    """
    if model_choice.lower() == "deepseek":
        model = 'deepseek-chat'
        return await translate_with_model(
            numbered_sentences_chunks, 
            custom_prompt, 
            model=model,
            api_key=DEEPSEEK_API_KEY,
            special_terms=special_terms, 
            content_name=content_name,
            video_id=video_id
        )
    elif model_choice.lower() == "gpt":
        model = 'gpt-4.1-mini'
        return await translate_with_model(
            numbered_sentences_chunks, 
            custom_prompt, 
            model=model,
            api_key=OPENAI_API_KEY,
            special_terms=special_terms, 
            content_name=content_name,
            video_id=video_id
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹é€‰æ‹©: {model_choice}ï¼Œè¯·é€‰æ‹© 'deepseek' æˆ– 'gpt'")

async def translate_with_model(numbered_sentences_chunks, custom_prompt, model, api_key, special_terms="", content_name="", video_id="unknown"):
    """
    ç»Ÿä¸€çš„æ¨¡å‹ç¿»è¯‘å®ç°å‡½æ•°
    """
    items = list(numbered_sentences_chunks.items())
    total_translated_dict = {}

    # å¤„ç†ç‰¹æ®Šæœ¯è¯­
    if special_terms:
        special_terms = special_terms.rstrip(".")
        special_terms_list = special_terms.split(", ")

    # åˆ›å»ºä¿¡å·é‡
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS)
    
    # åŸºäºæ¨¡å‹ç±»å‹åˆ›å»ºé€‚å½“çš„å®¢æˆ·ç«¯
    if "deepseek" in model.lower():
        client = AsyncOpenAI(
            api_key=api_key, 
            base_url="https://api.deepseek.com",  # DeepSeekçš„APIåœ°å€
            timeout=API_TIMEOUT
        )
        logger.info(f"ä½¿ç”¨DeepSeek APIå®¢æˆ·ç«¯ï¼Œæ¨¡å‹: {model}")
    elif "gpt" in model.lower():
        client = AsyncOpenAI(
            api_key=api_key,
            timeout=API_TIMEOUT
        )
        logger.info(f"ä½¿ç”¨OpenAI APIå®¢æˆ·ç«¯ï¼Œæ¨¡å‹: {model}")
    else:
        # å¤„ç†æœªçŸ¥æ¨¡å‹ç±»å‹
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model}")

    # è·å–é€‚åˆå½“å‰æ¨¡å‹çš„æç¤ºè¯
    system_prompt = get_system_prompt_for_model(model)

    # åˆ›å»ºæ‰¹æ¬¡å¤„ç†ä»»åŠ¡
    tasks = []
    for i in range(0, len(items), BATCH_SIZE):
        chunk = items[i:i + BATCH_SIZE]
        tasks.append(
            process_chunk(chunk, custom_prompt, model, client, semaphore, system_prompt, video_id)
        )
        logger.debug(f"ä»»åŠ¡åºå·: {i}")
    
    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # å¤„ç†ç»“æœ
    for result in results:
        if isinstance(result, Exception):
            logger.error(f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {str(result)}")
            continue
        
        # æ›´æ–°ç¿»è¯‘ç»“æœ
        translations = result.get('translations', {})
        total_translated_dict.update(translations)

    logger.info(f'ä½¿ç”¨çš„æ¨¡å‹ï¼š{model}')

    return total_translated_dict

def get_system_prompt_for_model(model):
    """
    æ ¹æ®ä¸åŒæ¨¡å‹è¿”å›é€‚åˆçš„ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
    """
    if "deepseek" in model.lower():
        # DeepSeek çš„æç¤ºè¯åŒ…å«å¤„ç†åˆ†å‰²å¥å­çš„è¯¦ç»†è¯´æ˜
        return """
        # Role
        You are a skilled translator specializing in converting English subtitles into natural and fluent Chinese while maintaining the original meaning.

        # Background information of the translation content
        {custom_prompt}
        Please identify the professional domain of the video content based on the information provided above, and leverage domain-specific knowledge and terminology to deliver an accurate and contextually appropriate translation.

        ## Skills
        ### Skill 1: Line-by-Line Translation
        - Emphasize the importance of translating English subtitles line by line to ensure accuracy and coherence.
        - Strictly follow the rule of translating each subtitle line individually based on the input content.
        In cases where a sentence is split, such as:
        125.    But what's even more impressive is their U.S.
        126.    commercial revenue projection.

        Step 1: Merge the split sentence into a complete sentence.
        Step 2: Translate the merged sentence into Chinese.
        Step 3: When outputting the Chinese translation, insert the translated result into both of the original split sentence positions.

        Example of this process:
          125.    But what's even more impressive is their U.S.
        ä½†æ›´ä»¤äººå°è±¡æ·±åˆ»çš„æ˜¯ä»–ä»¬çš„ç¾å›½ä¸šåŠ¡
          126.    commercial revenue projection.
        ä½†æ›´ä»¤äººå°è±¡æ·±åˆ»çš„æ˜¯ä»–ä»¬çš„ç¾å›½ä¸šåŠ¡

        ### Skill 2: Contextual Translation
        - Consider the context of the video to ensure accuracy and coherence in the translation.
        - When slang or implicit information appears in the original text, do not translate it literally. Instead, adapt it to align with natural Chinese communication habits.

        ### Skill 3: Handling Complex Sentences
        - Rearrange word order and adjust wording for complex sentence structures to ensure translations are easily understandable and fluent in Chinese.

        ### Skill 4: Proper Nouns and Special Terms
        - Identify proper nouns and special terms enclosed in angle brackets < > within the subtitle text, and retain them in their original English form.

        ### Skill 5: Ignore spelling errors
        - The English content is automatically generated by ASR and may contain spelling errors. Please ignore such errors and translate normally when encountered.

        ## Constraints
        - For punctuation requirements: Do not add a period when the sentence ends
        - The provided subtitles range from line {first_item_number} to line {end_item_number}, totaling {check_chunk_string} lines.
        - Provide the Chinese translation in the specified JSON format:
          ```
          {{
          "1": "<Translation of subtitle line 1>",
          "2": "<Translation of subtitle line 2>",
          "3": "<Translation of subtitle line 3>",
          ...
          }}
          ```
        """
    else:
        # GPT-4.1-mini çš„ç®€åŒ–æç¤ºè¯
        return """
        # Role
        You are a skilled translator specializing in converting English subtitles into natural and fluent Chinese while maintaining the original meaning.

        # Background information of the translation content
        {custom_prompt}
        Please identify the professional domain of the video content based on the information provided above, and leverage domain-specific knowledge and terminology to deliver an accurate and contextually appropriate translation.

        ## Skills
        ### Skill 1: Line-by-Line Translation
        - Emphasize the importance of translating English subtitles line by line to ensure accuracy and coherence.
        - Strictly follow the rule of translating each subtitle line individually based on the input content.

        ### Skill 2: Contextual Translation
        - Consider the context of the video to ensure accuracy and coherence in the translation.
        - When slang or implicit information appears in the original text, do not translate it literally. Instead, adapt it to align with natural Chinese communication habits.

        ### Skill 3: Handling Complex Sentences
        - Rearrange word order and adjust wording for complex sentence structures to ensure translations are easily understandable and fluent in Chinese.

        ### Skill 4: Proper Nouns and Special Terms
        - Identify proper nouns and special terms enclosed in angle brackets
         < > within the subtitle text, and retain them in their original English form.

        ## Constraints
        - For punctuation requirements: Do not add a period when the sentence ends
        - The provided subtitles range from line {first_item_number} to line {end_item_number}, totaling {check_chunk_string} lines.
        - Provide the Chinese translation in the specified JSON format:
          ```
          {{
          "1": "<Translation of subtitle line 1>",
          "2": "<Translation of subtitle line 2>",
          "3": "<Translation of subtitle line 3>",
          ...
          }}
          ```
        """

# 0505æ›´æ–° å°†titleå’Œchannel nameä¼ ç»™LLMï¼Œæ¨æ–­è§†é¢‘ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
@async_retry()
async def get_video_context_from_llm(title, channel_name):
    """
    è®©LLMé€šè¿‡title å’Œ channel name æ¨æ–­è§†é¢‘ä¸Šä¸‹æ–‡ä¿¡æ¯
    """
    try:
        logger.info("å¼€å§‹æ‰§è¡Œget_video_context_from_llm...")

        client = AsyncOpenAI(
            api_key=OPENAI_API_KEY,
            timeout=API_TIMEOUT
        )

        messages=[
                    {"role": "system", "content": "æ­¥éª¤1ï¼šåˆ¤æ–­è¯¥channelæ˜¯å¦æ˜¯åœ¨ä½ çš„çŸ¥è¯†åº“ä¸­ã€‚å¦‚æœä½ äº†è§£è¯¥channelçš„ç›¸å…³ä¿¡æ¯ï¼Œè¾“å‡ºå®ƒçš„ç›¸å…³ä¿¡æ¯\nä¾‹å¦‚ï¼šchannel name ï¼š 3Blue1Brown\nè¿™ä¸ªé¢‘é“ä»¥åŠ¨ç”»å¯è§†åŒ–æ•°å­¦åŸç†é—»å\nè¦æ±‚ï¼šä»”ç»†æ£€æŸ¥ä½ çš„çŸ¥è¯†åº“ï¼Œå¦‚æœä½ ä¸çŸ¥é“è¿™ä¸ªchannelåˆ™è¯šå®çš„è¯´ä¸çŸ¥é“ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚\n\næ­¥éª¤2ï¼šç»“åˆvideo titleå’Œæ­¥éª¤1çš„ä¿¡æ¯ï¼Œè¾“å‡ºä½ å¯¹è§†é¢‘å†…å®¹çš„æ¨æ–­ã€‚ç„¶åç®€è¦æè¿°é’ˆå¯¹è¿™ä¸ªè§†é¢‘ï¼Œè¯¥é‡‡å–ä»€ä¹ˆæ ·çš„ç¿»è¯‘ç­–ç•¥ã€‚\nè¦æ±‚ï¼šå¦‚æœæ— æ³•ä»titleå’Œchannel nameä¸­æ¨æ–­è§†é¢‘å†…å®¹ï¼Œè¯·è¯šå®çš„è¯´ä¸çŸ¥é“ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚\n\næ­¥éª¤3ï¼šç»¼åˆæ­¥éª¤1ã€2ï¼Œä»¥ç¬¬ä¸€äººç§°çš„å£å»ç»™å‡ºç®€è¦çš„3ä¸ªç¿»è¯‘ç­–ç•¥æˆ–æ³¨æ„äº‹é¡¹ã€‚\n\t1.\tæ˜ç¡®æœ¬æ¬¡ç¿»è¯‘åº”é‡‡ç”¨çš„è¯è¯­é£æ ¼ï¼ˆå¦‚ï¼šæ­£å¼ã€å­¦æœ¯ã€è½»æ¾ã€å¹½é»˜ç­‰ï¼‰ï¼Œé£æ ¼åº”è´´åˆè§†é¢‘å†…å®¹å’Œç›®æ ‡è§‚ä¼—ï¼›\n\t2.\tè¯†åˆ«è¯¥è§†é¢‘ä¸­å¯èƒ½åŒ…å«çš„ä¸“ä¸šé¢†åŸŸæœ¯è¯­ï¼Œç®€è¦åˆ—ä¸¾ 2-3 ä¸ªä»£è¡¨æ€§æœ¯è¯­ï¼Œå¹¶æŒ‡å‡ºå®ƒä»¬åœ¨ç¿»è¯‘ä¸­åº”ä¿æŒå‡†ç¡®æ€§æˆ–é‡‡ç”¨è´´è¿‘æ¯è¯­ä¹ æƒ¯çš„è¡¨è¾¾ï¼›\n\t3.\tå¯è¡¥å……å…¶ä»–ç¿»è¯‘æŠ€å·§ï¼Œä½†ä¸å¾—åŒ…å«æ¨¡æ¿åŒ–å»ºè®®ï¼Œå¦‚â€œæœ¯è¯­é¦–æ¬¡å‡ºç°æ—¶è¿›è¡Œæ³¨é‡Šæˆ–ä¸¾ä¾‹è¯´æ˜â€è¿™ç±»é€šç”¨è¡¨è¿°åº”é¿å…ä½¿ç”¨ã€‚\nè¦æ±‚ï¼šå¦‚æœæ— æ³•ä»æ­¥éª¤1ã€2æ¨æ–­è§†é¢‘å†…å®¹ï¼Œè¯·è¯šå®çš„è¯´ä¸çŸ¥é“ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚\n\nä½¿ç”¨ä¸­æ–‡è¾“å‡ºæ‰€æœ‰å†…å®¹\nä½¿ç”¨å¦‚ä¸‹jsonæ ¼å¼è¿›è¡Œè¾“å‡º\n{\n\"step1\": {\n\"channel_name\": \"string\",\n\"channel_info\": \"string or null\",\n\"can_judge\": true\n},\n\"step2\": {\n\"video_title\": \"string\",\n\"content_inference\": \"string or null\",\n\"can_judge\": true\n},\n\"step3\": {\n\"translation_strategies\": [\n\"string or null\",\n\"string or null\",\n\"special_terms_strategies\"\n],\n\"can_judge\": true\n}"},
                    {"role": "user", "content": f"channel name: {channel_name}\nvideo title: {title}"}
                ]

        response = await client.chat.completions.create(
            model="gpt-4.1",
            response_format={'type': "json_object"},
            messages=messages,
            temperature=1,
            top_p=0.7  
        )

        result = response.choices[0].message.content

        logger.info(f"get_video_context_from_llm ç»“æœ: {result}")


        # æ£€æŸ¥å“åº”ç»“æ„
        if not hasattr(response, 'choices') or len(response.choices) == 0:
            logger.error("APIå“åº”ç¼ºå°‘choiceså­—æ®µ")
            raise ValueError("æ— æ•ˆçš„APIå“åº”ç»“æ„")

        message = response.choices[0].message
        if not hasattr(message, 'content'):
            logger.error("APIå“åº”ç¼ºå°‘contentå­—æ®µ")
            raise ValueError("å“åº”ä¸­ç¼ºå°‘ç¿»è¯‘å†…å®¹")

        # é¢„éªŒè¯JSONæ ¼å¼
        try:
            json.loads(message.content)
        except json.JSONDecodeError as e:
            logger.error(f"JSONé¢„éªŒè¯å¤±è´¥: {message.content[:100]}...")
            raise

        return result

    except openai.APIConnectionError as e:
        logger.error(f"APIè¿æ¥é”™è¯¯: {str(e)}")
        raise
    except openai.APITimeoutError as e:
        logger.error(f"APIè¶…æ—¶é”™è¯¯: {str(e)}")
        raise
    except openai.RateLimitError as e:
        logger.error(f"APIé€Ÿç‡é™åˆ¶é”™è¯¯: {str(e)}")
        raise
    except Exception as e:
        logger.error(f"å¼‚æ­¥APIè°ƒç”¨å¤±è´¥: {str(e)}")
        raise


def process_video_context_data(json_data):
    # å¤„ç† get_video_context_from_llm çš„è¾“å‡º
    if isinstance(json_data, str):
        data = json.loads(json_data)
    else:
        data = json_data
    
    # ä»»åŠ¡1: æå–can_judgeä¸ºtrueçš„å­—æ®µï¼Œè½¬ä¸ºçº¯æ–‡æœ¬
    text_output = []
    
    # éå†æ¯ä¸ªstep
    for step_key, step_value in data.items():
        # æ£€æŸ¥æ˜¯å¦åŒ…å«can_judgeä¸”ä¸ºtrue
        if step_value.get("can_judge", False) == True:
            # æå–ä¸åŒç±»å‹çš„å­—æ®µ
            if "channel_info" in step_value:
                text_output.append(step_value["channel_info"])
            if "content_inference" in step_value:
                text_output.append(step_value["content_inference"])
            if "translation_strategies" in step_value and isinstance(step_value["translation_strategies"], list):
                for strategy in step_value["translation_strategies"]:
                    text_output.append(strategy)
    
    # å°†æ–‡æœ¬åˆ—è¡¨è½¬æ¢ä¸ºæ¢è¡Œåˆ†éš”çš„å­—ç¬¦ä¸²
    formatted_text = "\n".join(text_output)
    logger.info(f"process_video_context_data ä»»åŠ¡1ç»“æœ: {formatted_text}")
    # ä»»åŠ¡2: æå–step3ä¸­çš„translation_strategies
    # ç›´æ¥è¿”å›ç­–ç•¥åˆ—è¡¨ï¼Œé¿å…ä¸å¿…è¦çš„åµŒå¥—
    translation_strategies = []
    if "step3" in data and "translation_strategies" in data["step3"]:
        translation_strategies = data["step3"]["translation_strategies"]
    logger.info(f"process_video_context_data ä»»åŠ¡2ç»“æœ: {translation_strategies}")
    
    # ç›´æ¥è¿”å›ä¸¤ä¸ªç‹¬ç«‹çš„å˜é‡ï¼Œè€Œä¸æ˜¯å­—å…¸
    return formatted_text, translation_strategies